{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip setuptools wheel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZnhwO7uCvtKq",
        "outputId": "f42c7b19-0b35-4f33-b6a9-657a28f6e92a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (24.3.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (75.6.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (0.45.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"numpy==1.24.4\" \"pandas==1.5.3\" \"scipy==1.10.1\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8syRwyswENq",
        "outputId": "b6431fff-1415-48e3-97cf-389244fcf4b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy==1.24.4 in /usr/local/lib/python3.10/dist-packages (1.24.4)\n",
            "Requirement already satisfied: pandas==1.5.3 in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: scipy==1.10.1 in /usr/local/lib/python3.10/dist-packages (1.10.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas==1.5.3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==1.5.3) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas==1.5.3) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"tensorflow==2.13.0\" \"ml-dtypes==0.3.1\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qeJAW0Tywckx",
        "outputId": "1947b162-c2bd-40d9-f9ec-6c5d45bccfff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow==2.13.0 in /usr/local/lib/python3.10/dist-packages (2.13.0)\n",
            "Requirement already satisfied: ml-dtypes==0.3.1 in /usr/local/lib/python3.10/dist-packages (0.3.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (24.3.25)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.68.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (3.12.1)\n",
            "Requirement already satisfied: keras<2.14,>=2.13.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (2.13.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (18.1.1)\n",
            "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.24.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (4.25.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (75.6.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.14,>=2.13 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (2.13.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (2.13.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (4.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.16.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.13.0) (0.45.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.1.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update && apt-get install -y build-essential libffi-dev libssl-dev"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AQ6w8-Px9Zb",
        "outputId": "e42a7e10-352a-4f79-8e89-84a05d3ba2e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,185 kB]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:10 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,514 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,224 kB]\n",
            "Get:14 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,619 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,454 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,513 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,738 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [33.8 kB]\n",
            "Fetched 20.7 MB in 6s (3,291 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "build-essential is already the newest version (12.9ubuntu3).\n",
            "libssl-dev is already the newest version (3.0.2-0ubuntu1.18).\n",
            "The following NEW packages will be installed:\n",
            "  libffi-dev\n",
            "0 upgraded, 1 newly installed, 0 to remove and 59 not upgraded.\n",
            "Need to get 63.7 kB of archives.\n",
            "After this operation, 336 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libffi-dev amd64 3.4.2-4 [63.7 kB]\n",
            "Fetched 63.7 kB in 1s (72.3 kB/s)\n",
            "Selecting previously unselected package libffi-dev:amd64.\n",
            "(Reading database ... 123630 files and directories currently installed.)\n",
            "Preparing to unpack .../libffi-dev_3.4.2-4_amd64.deb ...\n",
            "Unpacking libffi-dev:amd64 (3.4.2-4) ...\n",
            "Setting up libffi-dev:amd64 (3.4.2-4) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"gym==0.25.2\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqTM__t6ypOE",
        "outputId": "a1806298-fed6-4702-db8a-bb90df618935"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gym==0.25.2 in /usr/local/lib/python3.10/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym==0.25.2) (1.24.3)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym==0.25.2) (3.1.0)\n",
            "Requirement already satisfied: gym_notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym==0.25.2) (0.0.8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --no-deps \"stable-baselines3[extra]==1.6.2\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-WWj3hqy-vw",
        "outputId": "ea82ede4-de07-4f8b-edac-6d65056681c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting stable-baselines3==1.6.2 (from stable-baselines3[extra]==1.6.2)\n",
            "  Downloading stable_baselines3-1.6.2-py3-none-any.whl.metadata (4.1 kB)\n",
            "Downloading stable_baselines3-1.6.2-py3-none-any.whl (170 kB)\n",
            "Installing collected packages: stable-baselines3\n",
            "Successfully installed stable-baselines3-1.6.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyYAML==6.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IGCX6aCz0hT",
        "outputId": "e20257cd-1b7b-488f-af3a-52f4d8b98c40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyYAML==6.0\n",
            "  Downloading PyYAML-6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (2.0 kB)\n",
            "Downloading PyYAML-6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (682 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/682.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m682.2/682.2 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyYAML\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 6.0.2\n",
            "    Uninstalling PyYAML-6.0.2:\n",
            "      Successfully uninstalled PyYAML-6.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 1.4.20 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\n",
            "langchain-core 0.3.19 requires typing-extensions>=4.7, but you have typing-extensions 4.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed PyYAML-6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install aiohttp==3.8.1 websockets==9.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QXocBbG0Hiy",
        "outputId": "ab56253a-c127-4bd5-e3c5-a9a4947fbf49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting aiohttp==3.8.1\n",
            "  Downloading aiohttp-3.8.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (7.3 kB)\n",
            "Collecting websockets==9.1\n",
            "  Downloading websockets-9.1.tar.gz (76 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.8.1) (24.2.0)\n",
            "Collecting charset-normalizer<3.0,>=2.0 (from aiohttp==3.8.1)\n",
            "  Downloading charset_normalizer-2.1.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.8.1) (6.1.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.8.1) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.8.1) (1.17.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.8.1) (1.5.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.8.1) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp==3.8.1) (4.5.0)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.0->aiohttp==3.8.1) (3.10)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.0->aiohttp==3.8.1) (0.2.0)\n",
            "Downloading aiohttp-3.8.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\n",
            "Building wheels for collected packages: websockets\n",
            "  Building wheel for websockets (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for websockets: filename=websockets-9.1-cp310-cp310-linux_x86_64.whl size=97279 sha256=9dc63254f9edd1faaa126f082a3d178391abac4e6a9cb28a7d79b21cfa644696\n",
            "  Stored in directory: /root/.cache/pip/wheels/79/f7/4e/873eca27ecd6d7230caff265283a5a5112ad4cd1d945c022dd\n",
            "Successfully built websockets\n",
            "Installing collected packages: websockets, charset-normalizer, aiohttp\n",
            "  Attempting uninstall: charset-normalizer\n",
            "    Found existing installation: charset-normalizer 3.4.0\n",
            "    Uninstalling charset-normalizer-3.4.0:\n",
            "      Successfully uninstalled charset-normalizer-3.4.0\n",
            "  Attempting uninstall: aiohttp\n",
            "    Found existing installation: aiohttp 3.11.2\n",
            "    Uninstalling aiohttp-3.11.2:\n",
            "      Successfully uninstalled aiohttp-3.11.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain 0.3.7 requires aiohttp<4.0.0,>=3.8.3, but you have aiohttp 3.8.1 which is incompatible.\n",
            "tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.13.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiohttp-3.8.1 charset-normalizer-2.1.1 websockets-9.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import stable_baselines3\n",
        "print(\"gym and stable-baselines3 installed successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwS-sku_0MQ1",
        "outputId": "b39674f5-5d6c-4a2a-8af8-d20aca60ba1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/util.py:52: DeprecationWarning: jax.xla_computation is deprecated. Please use the AOT APIs; see https://jax.readthedocs.io/en/latest/aot.html. For example, replace xla_computation(f)(*xs) with jit(f).lower(*xs).compiler_ir('hlo'). See CHANGELOG.md for 0.4.30 for more examples.\n",
            "  from jax import xla_computation as _xla_computation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gym and stable-baselines3 installed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/AI4Finance-Foundation/FinRL.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35sqtFQk0bNj",
        "outputId": "72d4af5c-5168-43df-870b-f11c321d2c68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/AI4Finance-Foundation/FinRL.git\n",
            "  Cloning https://github.com/AI4Finance-Foundation/FinRL.git to /tmp/pip-req-build-e__6mqw0\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/AI4Finance-Foundation/FinRL.git /tmp/pip-req-build-e__6mqw0\n",
            "  Resolved https://github.com/AI4Finance-Foundation/FinRL.git to commit 083192a2abbdcaa195bd945b35853212cd8b00d8\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl (from finrl==0.3.6)\n",
            "  Cloning https://github.com/AI4Finance-Foundation/ElegantRL.git to /tmp/pip-install-rsa4astd/elegantrl_7c052a1a8da446eeb9fbc197a3a547f9\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/AI4Finance-Foundation/ElegantRL.git /tmp/pip-install-rsa4astd/elegantrl_7c052a1a8da446eeb9fbc197a3a547f9\n",
            "  Resolved https://github.com/AI4Finance-Foundation/ElegantRL.git to commit c2939fefe0e3ec55601ded49e39fdf9d7d781ea0\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: alpaca-trade-api<4,>=3 in /usr/local/lib/python3.10/dist-packages (from finrl==0.3.6) (3.2.0)\n",
            "Requirement already satisfied: ccxt<4,>=3 in /usr/local/lib/python3.10/dist-packages (from finrl==0.3.6) (3.1.60)\n",
            "Requirement already satisfied: exchange-calendars<5,>=4 in /usr/local/lib/python3.10/dist-packages (from finrl==0.3.6) (4.6)\n",
            "Requirement already satisfied: jqdatasdk<2,>=1 in /usr/local/lib/python3.10/dist-packages (from finrl==0.3.6) (1.9.6)\n",
            "Requirement already satisfied: pyfolio<0.10,>=0.9 in /usr/local/lib/python3.10/dist-packages (from finrl==0.3.6) (0.9.2)\n",
            "Requirement already satisfied: pyportfolioopt<2,>=1 in /usr/local/lib/python3.10/dist-packages (from finrl==0.3.6) (1.5.6)\n",
            "Requirement already satisfied: ray<3,>=2 in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (2.39.0)\n",
            "Requirement already satisfied: scikit-learn<2,>=1 in /usr/local/lib/python3.10/dist-packages (from finrl==0.3.6) (1.5.2)\n",
            "Requirement already satisfied: stable-baselines3>=2.0.0a5 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (2.5.0a0)\n",
            "Requirement already satisfied: stockstats<0.6,>=0.5 in /usr/local/lib/python3.10/dist-packages (from finrl==0.3.6) (0.5.4)\n",
            "Requirement already satisfied: wrds<4,>=3 in /usr/local/lib/python3.10/dist-packages (from finrl==0.3.6) (3.2.0)\n",
            "Requirement already satisfied: yfinance<0.3,>=0.2 in /usr/local/lib/python3.10/dist-packages (from finrl==0.3.6) (0.2.49)\n",
            "Requirement already satisfied: pandas>=0.18.1 in /usr/local/lib/python3.10/dist-packages (from alpaca-trade-api<4,>=3->finrl==0.3.6) (2.2.3)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.10/dist-packages (from alpaca-trade-api<4,>=3->finrl==0.3.6) (1.26.4)\n",
            "Requirement already satisfied: requests<3,>2 in /usr/local/lib/python3.10/dist-packages (from alpaca-trade-api<4,>=3->finrl==0.3.6) (2.32.3)\n",
            "Requirement already satisfied: urllib3<2,>1.24 in /usr/local/lib/python3.10/dist-packages (from alpaca-trade-api<4,>=3->finrl==0.3.6) (1.26.20)\n",
            "Requirement already satisfied: websocket-client<2,>=0.56.0 in /usr/local/lib/python3.10/dist-packages (from alpaca-trade-api<4,>=3->finrl==0.3.6) (1.8.0)\n",
            "Requirement already satisfied: websockets<11,>=9.0 in /usr/local/lib/python3.10/dist-packages (from alpaca-trade-api<4,>=3->finrl==0.3.6) (9.1)\n",
            "Requirement already satisfied: msgpack==1.0.3 in /usr/local/lib/python3.10/dist-packages (from alpaca-trade-api<4,>=3->finrl==0.3.6) (1.0.3)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from alpaca-trade-api<4,>=3->finrl==0.3.6) (3.11.9)\n",
            "Requirement already satisfied: PyYAML==6.0.1 in /usr/local/lib/python3.10/dist-packages (from alpaca-trade-api<4,>=3->finrl==0.3.6) (6.0.1)\n",
            "Requirement already satisfied: deprecation==2.1.0 in /usr/local/lib/python3.10/dist-packages (from alpaca-trade-api<4,>=3->finrl==0.3.6) (2.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from deprecation==2.1.0->alpaca-trade-api<4,>=3->finrl==0.3.6) (23.2)\n",
            "Requirement already satisfied: setuptools>=60.9.0 in /usr/local/lib/python3.10/dist-packages (from ccxt<4,>=3->finrl==0.3.6) (75.6.0)\n",
            "Requirement already satisfied: certifi>=2018.1.18 in /usr/local/lib/python3.10/dist-packages (from ccxt<4,>=3->finrl==0.3.6) (2024.8.30)\n",
            "Requirement already satisfied: cryptography>=2.6.1 in /usr/local/lib/python3.10/dist-packages (from ccxt<4,>=3->finrl==0.3.6) (43.0.3)\n",
            "Requirement already satisfied: aiodns>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from ccxt<4,>=3->finrl==0.3.6) (3.2.0)\n",
            "Requirement already satisfied: yarl>=1.7.2 in /usr/local/lib/python3.10/dist-packages (from ccxt<4,>=3->finrl==0.3.6) (1.17.2)\n",
            "Requirement already satisfied: pyluach in /usr/local/lib/python3.10/dist-packages (from exchange-calendars<5,>=4->finrl==0.3.6) (2.2.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from exchange-calendars<5,>=4->finrl==0.3.6) (0.12.1)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.10/dist-packages (from exchange-calendars<5,>=4->finrl==0.3.6) (2024.2)\n",
            "Requirement already satisfied: korean_lunar_calendar in /usr/local/lib/python3.10/dist-packages (from exchange-calendars<5,>=4->finrl==0.3.6) (0.3.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from jqdatasdk<2,>=1->finrl==0.3.6) (1.16.0)\n",
            "Requirement already satisfied: SQLAlchemy>=1.2.8 in /usr/local/lib/python3.10/dist-packages (from jqdatasdk<2,>=1->finrl==0.3.6) (2.0.36)\n",
            "Requirement already satisfied: pymysql>=0.7.6 in /usr/local/lib/python3.10/dist-packages (from jqdatasdk<2,>=1->finrl==0.3.6) (1.1.1)\n",
            "Requirement already satisfied: thriftpy2!=0.5.1,>=0.3.9 in /usr/local/lib/python3.10/dist-packages (from jqdatasdk<2,>=1->finrl==0.3.6) (0.5.2)\n",
            "Requirement already satisfied: ipython>=3.2.3 in /usr/local/lib/python3.10/dist-packages (from pyfolio<0.10,>=0.9->finrl==0.3.6) (7.34.0)\n",
            "Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from pyfolio<0.10,>=0.9->finrl==0.3.6) (3.8.0)\n",
            "Requirement already satisfied: pytz>=2014.10 in /usr/local/lib/python3.10/dist-packages (from pyfolio<0.10,>=0.9->finrl==0.3.6) (2024.2)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from pyfolio<0.10,>=0.9->finrl==0.3.6) (1.12.0)\n",
            "Requirement already satisfied: seaborn>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from pyfolio<0.10,>=0.9->finrl==0.3.6) (0.13.2)\n",
            "Requirement already satisfied: empyrical>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from pyfolio<0.10,>=0.9->finrl==0.3.6) (0.5.5)\n",
            "Requirement already satisfied: cvxpy>=1.1.19 in /usr/local/lib/python3.10/dist-packages (from pyportfolioopt<2,>=1->finrl==0.3.6) (1.5.4)\n",
            "Requirement already satisfied: ecos<3.0.0,>=2.0.14 in /usr/local/lib/python3.10/dist-packages (from pyportfolioopt<2,>=1->finrl==0.3.6) (2.0.14)\n",
            "Requirement already satisfied: plotly<6.0.0,>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from pyportfolioopt<2,>=1->finrl==0.3.6) (5.24.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.6) (8.1.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.6) (3.16.1)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.6) (4.23.0)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.6) (4.25.5)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.6) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.6) (1.5.0)\n",
            "Requirement already satisfied: aiohttp-cors in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (0.7.0)\n",
            "Requirement already satisfied: colorful in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (0.5.6)\n",
            "Requirement already satisfied: py-spy>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (0.4.0)\n",
            "Requirement already satisfied: opencensus in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (0.11.4)\n",
            "Requirement already satisfied: pydantic!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3 in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (2.9.2)\n",
            "Requirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (0.21.0)\n",
            "Requirement already satisfied: smart-open in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (7.0.5)\n",
            "Requirement already satisfied: virtualenv!=20.21.1,>=20.0.24 in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (20.28.0)\n",
            "Requirement already satisfied: grpcio>=1.42.0 in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (1.68.0)\n",
            "Requirement already satisfied: memray in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (1.14.0)\n",
            "Requirement already satisfied: tensorboardX>=1.9 in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (2.6.2.2)\n",
            "Requirement already satisfied: pyarrow>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (17.0.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (2024.10.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2,>=1->finrl==0.3.6) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2,>=1->finrl==0.3.6) (3.5.0)\n",
            "Requirement already satisfied: gymnasium<1.1.0,>=0.29.1 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (1.0.0)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (2.5.1+cu121)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (3.1.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (4.10.0.84)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (2.6.1)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (2.13.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (5.9.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (4.66.6)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (13.9.4)\n",
            "Requirement already satisfied: ale-py>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (0.10.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (11.0.0)\n",
            "Requirement already satisfied: psycopg2-binary<2.10,>=2.9 in /usr/local/lib/python3.10/dist-packages (from wrds<4,>=3->finrl==0.3.6) (2.9.10)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from yfinance<0.3,>=0.2->finrl==0.3.6) (0.0.11)\n",
            "Requirement already satisfied: lxml>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from yfinance<0.3,>=0.2->finrl==0.3.6) (5.3.0)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from yfinance<0.3,>=0.2->finrl==0.3.6) (4.3.6)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.10/dist-packages (from yfinance<0.3,>=0.2->finrl==0.3.6) (2.4.6)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.10/dist-packages (from yfinance<0.3,>=0.2->finrl==0.3.6) (3.17.8)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.10/dist-packages (from yfinance<0.3,>=0.2->finrl==0.3.6) (4.12.3)\n",
            "Requirement already satisfied: html5lib>=1.1 in /usr/local/lib/python3.10/dist-packages (from yfinance<0.3,>=0.2->finrl==0.3.6) (1.1)\n",
            "Requirement already satisfied: th in /usr/local/lib/python3.10/dist-packages (from elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl->finrl==0.3.6) (0.4.1)\n",
            "Requirement already satisfied: pycares>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from aiodns>=1.1.1->ccxt<4,>=3->finrl==0.3.6) (4.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4,>=3.8.3->alpaca-trade-api<4,>=3->finrl==0.3.6) (2.4.3)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4,>=3.8.3->alpaca-trade-api<4,>=3->finrl==0.3.6) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4,>=3.8.3->alpaca-trade-api<4,>=3->finrl==0.3.6) (24.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4,>=3.8.3->alpaca-trade-api<4,>=3->finrl==0.3.6) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4,>=3.8.3->alpaca-trade-api<4,>=3->finrl==0.3.6) (0.2.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from ale-py>=0.9.0->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (4.12.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.11.1->yfinance<0.3,>=0.2->finrl==0.3.6) (2.6)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=2.6.1->ccxt<4,>=3->finrl==0.3.6) (1.17.1)\n",
            "Requirement already satisfied: osqp>=0.6.2 in /usr/local/lib/python3.10/dist-packages (from cvxpy>=1.1.19->pyportfolioopt<2,>=1->finrl==0.3.6) (0.6.7.post3)\n",
            "Requirement already satisfied: clarabel>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from cvxpy>=1.1.19->pyportfolioopt<2,>=1->finrl==0.3.6) (0.9.0)\n",
            "Requirement already satisfied: scs>=3.2.4.post1 in /usr/local/lib/python3.10/dist-packages (from cvxpy>=1.1.19->pyportfolioopt<2,>=1->finrl==0.3.6) (3.2.7)\n",
            "Requirement already satisfied: pandas-datareader>=0.2 in /usr/local/lib/python3.10/dist-packages (from empyrical>=0.5.0->pyfolio<0.10,>=0.9->finrl==0.3.6) (0.10.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium<1.1.0,>=0.29.1->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (0.0.4)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance<0.3,>=0.2->finrl==0.3.6) (0.5.1)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (4.9.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->pyfolio<0.10,>=0.9->finrl==0.3.6) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->pyfolio<0.10,>=0.9->finrl==0.3.6) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->pyfolio<0.10,>=0.9->finrl==0.3.6) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->pyfolio<0.10,>=0.9->finrl==0.3.6) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->pyfolio<0.10,>=0.9->finrl==0.3.6) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->pyfolio<0.10,>=0.9->finrl==0.3.6) (2.8.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly<6.0.0,>=5.0.0->pyportfolioopt<2,>=1->finrl==0.3.6) (9.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3->ray[default,tune]<3,>=2->finrl==0.3.6) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3->ray[default,tune]<3,>=2->finrl==0.3.6) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>2->alpaca-trade-api<4,>=3->finrl==0.3.6) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>2->alpaca-trade-api<4,>=3->finrl==0.3.6) (3.10)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.2.8->jqdatasdk<2,>=1->finrl==0.3.6) (3.1.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (1.4.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (3.1.3)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (0.45.1)\n",
            "Requirement already satisfied: Cython>=3.0.10 in /usr/local/lib/python3.10/dist-packages (from thriftpy2!=0.5.1,>=0.3.9->jqdatasdk<2,>=1->finrl==0.3.6) (3.0.11)\n",
            "Requirement already satisfied: ply<4.0,>=3.4 in /usr/local/lib/python3.10/dist-packages (from thriftpy2!=0.5.1,>=0.3.9->jqdatasdk<2,>=1->finrl==0.3.6) (3.11)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (1.3.0)\n",
            "Requirement already satisfied: distlib<1,>=0.3.7 in /usr/local/lib/python3.10/dist-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<3,>=2->finrl==0.3.6) (0.3.9)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.6) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.6) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.6) (0.21.0)\n",
            "Requirement already satisfied: textual>=0.41.0 in /usr/local/lib/python3.10/dist-packages (from memray->ray[default,tune]<3,>=2->finrl==0.3.6) (0.88.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (3.0.0)\n",
            "Requirement already satisfied: opencensus-context>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from opencensus->ray[default,tune]<3,>=2->finrl==0.3.6) (0.1.3)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opencensus->ray[default,tune]<3,>=2->finrl==0.3.6) (2.19.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open->ray[default,tune]<3,>=2->finrl==0.3.6) (1.16.0)\n",
            "Requirement already satisfied: niltype<2.0,>=0.3 in /usr/local/lib/python3.10/dist-packages (from th->elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl->finrl==0.3.6) (1.0.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=2.6.1->ccxt<4,>=3->finrl==0.3.6) (2.22)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<3,>=2->finrl==0.3.6) (1.66.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<3,>=2->finrl==0.3.6) (1.25.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (1.3.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (0.8.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (3.0.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (0.1.2)\n",
            "Requirement already satisfied: qdldl in /usr/local/lib/python3.10/dist-packages (from osqp>=0.6.2->cvxpy>=1.1.19->pyportfolioopt<2,>=1->finrl==0.3.6) (0.1.7.post4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (0.2.13)\n",
            "Requirement already satisfied: linkify-it-py<3,>=1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify,plugins]>=2.1.0->textual>=0.41.0->memray->ray[default,tune]<3,>=2->finrl==0.3.6) (2.0.3)\n",
            "Requirement already satisfied: mdit-py-plugins in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify,plugins]>=2.1.0->textual>=0.41.0->memray->ray[default,tune]<3,>=2->finrl==0.3.6) (0.4.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (3.2.2)\n",
            "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.10/dist-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify,plugins]>=2.1.0->textual>=0.41.0->memray->ray[default,tune]<3,>=2->finrl==0.3.6) (1.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "5fJ4ljKu1qTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime"
      ],
      "metadata": {
        "id": "owymmwwb65C9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "XtPV08LR7EDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
        "from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
        "from finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
        "from finrl.agents.stablebaselines3.models import DRLAgent, DRLEnsembleAgent\n",
        "from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline"
      ],
      "metadata": {
        "id": "Br4rPq9OpUfr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abb992c6-6500-4c8b-abbc-5e8d912606cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pandas_datareader/compat/__init__.py:11: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
            "  PANDAS_VERSION = LooseVersion(pd.__version__)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3 import DQN"
      ],
      "metadata": {
        "id": "dBKKBt8z6mp3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from finrl.config import (\n",
        "    DATA_SAVE_DIR,\n",
        "    TRAINED_MODEL_DIR,\n",
        "    TENSORBOARD_LOG_DIR,\n",
        "    RESULTS_DIR,\n",
        "    INDICATORS,\n",
        "    TRAIN_START_DATE,\n",
        "    TRAIN_END_DATE,\n",
        "    TEST_START_DATE,\n",
        "    TEST_END_DATE,\n",
        "    TRADE_START_DATE,\n",
        "    TRADE_END_DATE,\n",
        ")"
      ],
      "metadata": {
        "id": "k0CcQ1qYpXoF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from finrl.main import check_and_make_directories\n",
        "import os"
      ],
      "metadata": {
        "id": "hb2rvmn5pdkw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "check_and_make_directories([DATA_SAVE_DIR, TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR, RESULTS_DIR])"
      ],
      "metadata": {
        "id": "C0oPmrJGpfKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_START_DATE = \"2012-01-01\"\n",
        "TRAIN_END_DATE = \"2018-12-31\"\n",
        "TEST_START_DATE = \"2019-01-01\"\n",
        "TEST_END_DATE = \"2022-12-31\""
      ],
      "metadata": {
        "id": "lkTofjogphCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ticker = ['AAPL', 'MSFT', 'TSLA']\n",
        "df = YahooDownloader(start_date = TRAIN_START_DATE,\n",
        "                     end_date = TEST_END_DATE,\n",
        "                     ticker_list = ticker).fetch_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8E8rzKoxptKy",
        "outputId": "4607c9ef-f285-4200-8988-7fff59958ae4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of DataFrame:  (8304, 8)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "JAc4NuZnqxjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail()"
      ],
      "metadata": {
        "id": "nC8z54e8q5vx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "OKHwjUXbq7YU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.sort_values(['date','tic']).head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "id": "rchKj6jgrCFg",
        "outputId": "731f83f4-f5c5-4734-a13d-86d6e281d0ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         date       open       high        low      close     volume   tic  \\\n",
              "0  2012-01-03  12.388996  14.686786  14.732143  14.621429  302220800  AAPL   \n",
              "1  2012-01-03  21.120100  26.770000  26.959999  26.549999   64731500  MSFT   \n",
              "2  2012-01-03   1.872000   1.872000   1.966667   1.929333   13921500  TSLA   \n",
              "3  2012-01-04  12.455578  14.765714  14.810000  14.642857  260022000  AAPL   \n",
              "4  2012-01-04  21.617132  27.400000  27.469999  26.820000   80516100  MSFT   \n",
              "\n",
              "   day  \n",
              "0    1  \n",
              "1    1  \n",
              "2    1  \n",
              "3    2  \n",
              "4    2  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-96563429-d438-4c19-9b24-2156f5dfc202\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>tic</th>\n",
              "      <th>day</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2012-01-03</td>\n",
              "      <td>12.388996</td>\n",
              "      <td>14.686786</td>\n",
              "      <td>14.732143</td>\n",
              "      <td>14.621429</td>\n",
              "      <td>302220800</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2012-01-03</td>\n",
              "      <td>21.120100</td>\n",
              "      <td>26.770000</td>\n",
              "      <td>26.959999</td>\n",
              "      <td>26.549999</td>\n",
              "      <td>64731500</td>\n",
              "      <td>MSFT</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2012-01-03</td>\n",
              "      <td>1.872000</td>\n",
              "      <td>1.872000</td>\n",
              "      <td>1.966667</td>\n",
              "      <td>1.929333</td>\n",
              "      <td>13921500</td>\n",
              "      <td>TSLA</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2012-01-04</td>\n",
              "      <td>12.455578</td>\n",
              "      <td>14.765714</td>\n",
              "      <td>14.810000</td>\n",
              "      <td>14.642857</td>\n",
              "      <td>260022000</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2012-01-04</td>\n",
              "      <td>21.617132</td>\n",
              "      <td>27.400000</td>\n",
              "      <td>27.469999</td>\n",
              "      <td>26.820000</td>\n",
              "      <td>80516100</td>\n",
              "      <td>MSFT</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-96563429-d438-4c19-9b24-2156f5dfc202')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-96563429-d438-4c19-9b24-2156f5dfc202 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-96563429-d438-4c19-9b24-2156f5dfc202');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d8bf2051-b7d0-4dc3-b096-a8c2b63791c8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d8bf2051-b7d0-4dc3-b096-a8c2b63791c8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d8bf2051-b7d0-4dc3-b096-a8c2b63791c8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"2012-01-04\",\n          \"2012-01-03\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"open\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.073503255989383,\n        \"min\": 1.871999979019165,\n        \"max\": 21.61713218688965,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          21.120100021362305,\n          21.61713218688965\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"high\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10.52097162123572,\n        \"min\": 1.871999979019165,\n        \"max\": 27.399999618530273,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          26.770000457763672,\n          27.399999618530273\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10.542610752637342,\n        \"min\": 1.9666670560836792,\n        \"max\": 27.469999313354492,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          26.959999084472656,\n          27.469999313354492\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10.31910268830665,\n        \"min\": 1.929332971572876,\n        \"max\": 26.81999969482422,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          26.549999237060547,\n          26.81999969482422\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"volume\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 128187991,\n        \"min\": 13921500,\n        \"max\": 302220800,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          64731500,\n          80516100\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tic\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"AAPL\",\n          \"MSFT\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"day\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "INDICATORS = ['macd',\n",
        "               'rsi_30',\n",
        "               'cci_30',\n",
        "               'dx_30']"
      ],
      "metadata": {
        "id": "FKj2QxLLrLnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fe = FeatureEngineer(use_technical_indicator=True,\n",
        "                     tech_indicator_list = INDICATORS,\n",
        "                     use_turbulence=True,\n",
        "                     user_defined_feature = False)\n",
        "\n",
        "processed = fe.preprocess_data(df)\n",
        "processed = processed.copy()\n",
        "processed = processed.fillna(0)\n",
        "processed = processed.replace(np.inf,0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlSCxwbirO7u",
        "outputId": "4dee44a2-eff0-49a5-b14e-5b3863704c37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully added technical indicators\n",
            "Successfully added turbulence index\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processed.sample(5)"
      ],
      "metadata": {
        "id": "CixIcTsEsEc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stock_dimension = len(processed.tic.unique())\n",
        "state_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\n",
        "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWWbsdZFsIoh",
        "outputId": "46fe861a-56e4-4344-93a2-d8c4bebb1d4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stock Dimension: 3, State Space: 19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env_kwargs = {\n",
        "    \"hmax\": 100,\n",
        "    \"initial_amount\": 1000000,\n",
        "    \"buy_cost_pct\": 0.001,\n",
        "    \"sell_cost_pct\": 0.001,\n",
        "    \"state_space\": state_space,\n",
        "    \"stock_dim\": stock_dimension,\n",
        "    \"tech_indicator_list\": INDICATORS,\n",
        "    \"action_space\": stock_dimension,\n",
        "    \"reward_scaling\": 1e-4,\n",
        "    \"print_verbosity\":5\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "vFtleu10shqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rebalance_window = 63 # rebalance_window is the number of days to retrain the model\n",
        "validation_window = 63 # validation_window is the number of days to do validation and trading (e.g. if validation_window=63, then both validation and trading period will be 63 days)\n",
        "\n"
      ],
      "metadata": {
        "id": "ok-IOeKltGtn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries and check GPU\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "print(\"Num GPUs Available (TensorFlow): \", len(tf.config.list_physical_devices('GPU')))\n",
        "print(\"PyTorch GPU Available: \", torch.cuda.is_available())\n",
        "\n",
        "# Modify DRLEnsembleAgent to use GPU\n",
        "ensemble_agent = DRLEnsembleAgent(\n",
        "    df=processed,\n",
        "    train_period=(TRAIN_START_DATE, TRAIN_END_DATE),\n",
        "    val_test_period=(TEST_START_DATE, TEST_END_DATE),\n",
        "    rebalance_window=rebalance_window,\n",
        "    validation_window=validation_window,\n",
        "    **env_kwargs\n",
        ")\n",
        "\n",
        "# Add 'device': 'cuda' to model kwargs\n",
        "A2C_model_kwargs = {\n",
        "    'n_steps': 5,\n",
        "    'ent_coef': 0.005,\n",
        "    'learning_rate': 0.0007,\n",
        "    'device': 'cuda'\n",
        "}\n",
        "PPO_model_kwargs = {\n",
        "    \"ent_coef\": 0.01,\n",
        "    \"n_steps\": 2048,\n",
        "    \"learning_rate\": 0.00025,\n",
        "    \"batch_size\": 128,\n",
        "    \"device\": \"cuda\"\n",
        "}\n",
        "DDPG_model_kwargs = {\n",
        "    \"buffer_size\": 10_000,\n",
        "    \"learning_rate\": 0.0005,\n",
        "    \"batch_size\": 64,\n",
        "    \"device\": \"cuda\"\n",
        "}\n",
        "\n",
        "TD3_model_kwargs = {\"device\": \"cuda\"}\n",
        "SAC_model_kwargs = {\"device\": \"cuda\"}\n",
        "\n",
        "timesteps_dict = {'a2c' : 10_000,\n",
        "                 'ppo' : 10_000,\n",
        "                 'ddpg' : 10_000,\n",
        "                  \"td3\": 10_000,\n",
        "                  \"sac\": 10_000\n",
        "                 }"
      ],
      "metadata": {
        "id": "huqXQvlzyoJY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c480b3c1-19b0-4da2-86e8-f8640afdc527"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available (TensorFlow):  0\n",
            "PyTorch GPU Available:  True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_summary = ensemble_agent.run_ensemble_strategy(\n",
        "    A2C_model_kwargs=A2C_model_kwargs,\n",
        "    PPO_model_kwargs=PPO_model_kwargs,\n",
        "    DDPG_model_kwargs=DDPG_model_kwargs,\n",
        "    TD3_model_kwargs=TD3_model_kwargs,\n",
        "    SAC_model_kwargs=SAC_model_kwargs,\n",
        "    timesteps_dict=timesteps_dict\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C56ps-hv8rOz",
        "outputId": "721e6f1c-da39-436e-91e5-fc9cee01c51b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "|    critic_loss     | 11.6      |\n",
            "|    learning_rate   | 0.0005    |\n",
            "|    n_updates       | 7695      |\n",
            "|    reward          | 5.5529985 |\n",
            "----------------------------------\n",
            "======ddpg Validation from:  2019-10-02 to  2020-01-02\n",
            "ddpg Sharpe Ratio:  0.6149495396801921\n",
            "======td3 Training========\n",
            "{'device': 'cuda'}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/td3/td3_315_1\n",
            "day: 1948, episode: 15\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 3839493.85\n",
            "total_reward: 2839493.85\n",
            "total_cost: 999.00\n",
            "total_trades: 5652\n",
            "Sharpe: 0.963\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 4         |\n",
            "|    fps             | 128       |\n",
            "|    time_elapsed    | 60        |\n",
            "|    total_timesteps | 7796      |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 172       |\n",
            "|    critic_loss     | 599       |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 7695      |\n",
            "|    reward          | 5.1824408 |\n",
            "----------------------------------\n",
            "======td3 Validation from:  2019-10-02 to  2020-01-02\n",
            "td3 Sharpe Ratio:  0.44960660570223726\n",
            "======sac Training========\n",
            "{'device': 'cuda'}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/sac/sac_315_1\n",
            "day: 1948, episode: 20\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 2997156.62\n",
            "total_reward: 1997156.62\n",
            "total_cost: 998.99\n",
            "total_trades: 1948\n",
            "Sharpe: 0.714\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 4         |\n",
            "|    fps             | 73        |\n",
            "|    time_elapsed    | 106       |\n",
            "|    total_timesteps | 7796      |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 7.93e+03  |\n",
            "|    critic_loss     | 2.64e+05  |\n",
            "|    ent_coef        | 9.28      |\n",
            "|    ent_coef_loss   | -113      |\n",
            "|    learning_rate   | 0.0003    |\n",
            "|    n_updates       | 7695      |\n",
            "|    reward          | 5.5529985 |\n",
            "----------------------------------\n",
            "======sac Validation from:  2019-10-02 to  2020-01-02\n",
            "sac Sharpe Ratio:  0.6149495396801921\n",
            "======ppo Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128, 'device': 'cuda'}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ppo/ppo_315_1\n",
            "day: 1948, episode: 25\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152322.40\n",
            "total_reward: 152322.40\n",
            "total_cost: 12861.06\n",
            "total_trades: 5696\n",
            "Sharpe: 0.513\n",
            "=================================\n",
            "------------------------------------\n",
            "| time/              |             |\n",
            "|    fps             | 420         |\n",
            "|    iterations      | 1           |\n",
            "|    time_elapsed    | 4           |\n",
            "|    total_timesteps | 2048        |\n",
            "| train/             |             |\n",
            "|    reward          | 0.009345047 |\n",
            "------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 361        |\n",
            "|    iterations           | 2          |\n",
            "|    time_elapsed         | 11         |\n",
            "|    total_timesteps      | 4096       |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00451951 |\n",
            "|    clip_fraction        | 0.014      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -4.25      |\n",
            "|    explained_variance   | 0.00435    |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | 0.11       |\n",
            "|    n_updates            | 10         |\n",
            "|    policy_gradient_loss | 3.17e-05   |\n",
            "|    reward               | 0.09372607 |\n",
            "|    std                  | 0.997      |\n",
            "|    value_loss           | 0.297      |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 363          |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 16           |\n",
            "|    total_timesteps      | 6144         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0040866947 |\n",
            "|    clip_fraction        | 0.0479       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -4.25        |\n",
            "|    explained_variance   | -0.00114     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.812        |\n",
            "|    n_updates            | 20           |\n",
            "|    policy_gradient_loss | -0.00331     |\n",
            "|    reward               | 0.047445234  |\n",
            "|    std                  | 0.995        |\n",
            "|    value_loss           | 1.74         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 350         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 23          |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004697258 |\n",
            "|    clip_fraction        | 0.0335      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.24       |\n",
            "|    explained_variance   | -0.0253     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 3.12        |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.00363    |\n",
            "|    reward               | 0.0677746   |\n",
            "|    std                  | 0.994       |\n",
            "|    value_loss           | 7.27        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 353         |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 28          |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002534104 |\n",
            "|    clip_fraction        | 0.00625     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.24       |\n",
            "|    explained_variance   | 0.057       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 6.99        |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.00204    |\n",
            "|    reward               | -0.18809615 |\n",
            "|    std                  | 0.994       |\n",
            "|    value_loss           | 17          |\n",
            "-----------------------------------------\n",
            "======ppo Validation from:  2019-10-02 to  2020-01-02\n",
            "ppo Sharpe Ratio:  0.37829306764141624\n",
            "======Best Model Retraining from:  2012-01-01 to  2020-01-02\n",
            "======Trading from:  2020-01-02 to  2020-04-02\n",
            "============================================\n",
            "turbulence_threshold:  24.528961738292235\n",
            "======Model training from:  2012-01-01 to  2020-01-02\n",
            "======a2c Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007, 'device': 'cuda'}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/a2c/a2c_378_1\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 295        |\n",
            "|    iterations         | 100        |\n",
            "|    time_elapsed       | 1          |\n",
            "|    total_timesteps    | 500        |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.28      |\n",
            "|    explained_variance | 0.0137     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 99         |\n",
            "|    policy_loss        | -9.64      |\n",
            "|    reward             | -1.2144631 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 5.08       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 251       |\n",
            "|    iterations         | 200       |\n",
            "|    time_elapsed       | 3         |\n",
            "|    total_timesteps    | 1000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.28     |\n",
            "|    explained_variance | 0.149     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 199       |\n",
            "|    policy_loss        | 0.568     |\n",
            "|    reward             | 1.8618492 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 2.19      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 247       |\n",
            "|    iterations         | 300       |\n",
            "|    time_elapsed       | 6         |\n",
            "|    total_timesteps    | 1500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.28     |\n",
            "|    explained_variance | 0.00177   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 299       |\n",
            "|    policy_loss        | 14.8      |\n",
            "|    reward             | 5.1400733 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 26.2      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 258      |\n",
            "|    iterations         | 400      |\n",
            "|    time_elapsed       | 7        |\n",
            "|    total_timesteps    | 2000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.3     |\n",
            "|    explained_variance | 0.047    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 399      |\n",
            "|    policy_loss        | 10.5     |\n",
            "|    reward             | 4.775307 |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 36.9     |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 265        |\n",
            "|    iterations         | 500        |\n",
            "|    time_elapsed       | 9          |\n",
            "|    total_timesteps    | 2500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.31      |\n",
            "|    explained_variance | -0.15      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 499        |\n",
            "|    policy_loss        | 8.09       |\n",
            "|    reward             | -1.1147498 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 4.6        |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 270      |\n",
            "|    iterations         | 600      |\n",
            "|    time_elapsed       | 11       |\n",
            "|    total_timesteps    | 3000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.3     |\n",
            "|    explained_variance | 0.111    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 599      |\n",
            "|    policy_loss        | 1.46     |\n",
            "|    reward             | 4.685404 |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 0.628    |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 273       |\n",
            "|    iterations         | 700       |\n",
            "|    time_elapsed       | 12        |\n",
            "|    total_timesteps    | 3500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.31     |\n",
            "|    explained_variance | 0.217     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 699       |\n",
            "|    policy_loss        | 9.67      |\n",
            "|    reward             | -4.017472 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 8.02      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 275       |\n",
            "|    iterations         | 800       |\n",
            "|    time_elapsed       | 14        |\n",
            "|    total_timesteps    | 4000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.3      |\n",
            "|    explained_variance | 0.0583    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 799       |\n",
            "|    policy_loss        | 29.1      |\n",
            "|    reward             | 2.2001672 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 43.2      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 271       |\n",
            "|    iterations         | 900       |\n",
            "|    time_elapsed       | 16        |\n",
            "|    total_timesteps    | 4500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.29     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 899       |\n",
            "|    policy_loss        | 3.7       |\n",
            "|    reward             | 0.6734398 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 1.61      |\n",
            "-------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 265            |\n",
            "|    iterations         | 1000           |\n",
            "|    time_elapsed       | 18             |\n",
            "|    total_timesteps    | 5000           |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -4.31          |\n",
            "|    explained_variance | 5.96e-08       |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 999            |\n",
            "|    policy_loss        | -17            |\n",
            "|    reward             | -0.00020791283 |\n",
            "|    std                | 1.02           |\n",
            "|    value_loss         | 14.7           |\n",
            "------------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 268        |\n",
            "|    iterations         | 1100       |\n",
            "|    time_elapsed       | 20         |\n",
            "|    total_timesteps    | 5500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.32      |\n",
            "|    explained_variance | 0.0286     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1099       |\n",
            "|    policy_loss        | 10         |\n",
            "|    reward             | -1.3108854 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 8.27       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 270       |\n",
            "|    iterations         | 1200      |\n",
            "|    time_elapsed       | 22        |\n",
            "|    total_timesteps    | 6000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.32     |\n",
            "|    explained_variance | -0.00401  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1199      |\n",
            "|    policy_loss        | 13.1      |\n",
            "|    reward             | 0.4933951 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 30.6      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 271       |\n",
            "|    iterations         | 1300      |\n",
            "|    time_elapsed       | 23        |\n",
            "|    total_timesteps    | 6500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.33     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1299      |\n",
            "|    policy_loss        | 2.38      |\n",
            "|    reward             | 1.6204606 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 1.1       |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 273        |\n",
            "|    iterations         | 1400       |\n",
            "|    time_elapsed       | 25         |\n",
            "|    total_timesteps    | 7000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.35      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1399       |\n",
            "|    policy_loss        | 19         |\n",
            "|    reward             | -0.4896021 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 22.1       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 274       |\n",
            "|    iterations         | 1500      |\n",
            "|    time_elapsed       | 27        |\n",
            "|    total_timesteps    | 7500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.35     |\n",
            "|    explained_variance | -1.33     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1499      |\n",
            "|    policy_loss        | 2.16      |\n",
            "|    reward             | 1.3350792 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 2         |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 272        |\n",
            "|    iterations         | 1600       |\n",
            "|    time_elapsed       | 29         |\n",
            "|    total_timesteps    | 8000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.33      |\n",
            "|    explained_variance | -0.00584   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1599       |\n",
            "|    policy_loss        | 15.6       |\n",
            "|    reward             | -3.1672325 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 14.9       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 266        |\n",
            "|    iterations         | 1700       |\n",
            "|    time_elapsed       | 31         |\n",
            "|    total_timesteps    | 8500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.33      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1699       |\n",
            "|    policy_loss        | 3.81       |\n",
            "|    reward             | 0.31497043 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 0.912      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 267       |\n",
            "|    iterations         | 1800      |\n",
            "|    time_elapsed       | 33        |\n",
            "|    total_timesteps    | 9000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.32     |\n",
            "|    explained_variance | -0.0266   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1799      |\n",
            "|    policy_loss        | 11.2      |\n",
            "|    reward             | 0.8390585 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 12        |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 268       |\n",
            "|    iterations         | 1900      |\n",
            "|    time_elapsed       | 35        |\n",
            "|    total_timesteps    | 9500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.32     |\n",
            "|    explained_variance | -0.0317   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1899      |\n",
            "|    policy_loss        | 6.4       |\n",
            "|    reward             | 0.7576214 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 2.43      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 269      |\n",
            "|    iterations         | 2000     |\n",
            "|    time_elapsed       | 37       |\n",
            "|    total_timesteps    | 10000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.32    |\n",
            "|    explained_variance | 0.0699   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1999     |\n",
            "|    policy_loss        | -9.24    |\n",
            "|    reward             | 1.017609 |\n",
            "|    std                | 1.02     |\n",
            "|    value_loss         | 6.99     |\n",
            "------------------------------------\n",
            "======a2c Validation from:  2020-01-02 to  2020-04-02\n",
            "a2c Sharpe Ratio:  0.009218556206298282\n",
            "======ddpg Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64, 'device': 'cuda'}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ddpg/ddpg_378_1\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 4        |\n",
            "|    fps             | 119      |\n",
            "|    time_elapsed    | 67       |\n",
            "|    total_timesteps | 8048     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 7.21e+03 |\n",
            "|    critic_loss     | 1.82e+05 |\n",
            "|    learning_rate   | 0.0005   |\n",
            "|    n_updates       | 7947     |\n",
            "|    reward          | 0.0      |\n",
            "---------------------------------\n",
            "======ddpg Validation from:  2020-01-02 to  2020-04-02\n",
            "ddpg Sharpe Ratio:  0.0\n",
            "======td3 Training========\n",
            "{'device': 'cuda'}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/td3/td3_378_1\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    episodes        | 4          |\n",
            "|    fps             | 126        |\n",
            "|    time_elapsed    | 63         |\n",
            "|    total_timesteps | 8048       |\n",
            "| train/             |            |\n",
            "|    actor_loss      | 5.42e+03   |\n",
            "|    critic_loss     | 4.7e+03    |\n",
            "|    learning_rate   | 0.001      |\n",
            "|    n_updates       | 7947       |\n",
            "|    reward          | -16.064917 |\n",
            "-----------------------------------\n",
            "======td3 Validation from:  2020-01-02 to  2020-04-02\n",
            "td3 Sharpe Ratio:  0.07395354121224185\n",
            "======sac Training========\n",
            "{'device': 'cuda'}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/sac/sac_378_1\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    episodes        | 4          |\n",
            "|    fps             | 72         |\n",
            "|    time_elapsed    | 110        |\n",
            "|    total_timesteps | 8048       |\n",
            "| train/             |            |\n",
            "|    actor_loss      | 1.56e+04   |\n",
            "|    critic_loss     | 2.93e+03   |\n",
            "|    ent_coef        | 10.8       |\n",
            "|    ent_coef_loss   | -175       |\n",
            "|    learning_rate   | 0.0003     |\n",
            "|    n_updates       | 7947       |\n",
            "|    reward          | -6.5354156 |\n",
            "-----------------------------------\n",
            "======sac Validation from:  2020-01-02 to  2020-04-02\n",
            "sac Sharpe Ratio:  -0.08883458754665745\n",
            "======ppo Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128, 'device': 'cuda'}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ppo/ppo_378_1\n",
            "------------------------------------\n",
            "| time/              |             |\n",
            "|    fps             | 351         |\n",
            "|    iterations      | 1           |\n",
            "|    time_elapsed    | 5           |\n",
            "|    total_timesteps | 2048        |\n",
            "| train/             |             |\n",
            "|    reward          | 0.020923166 |\n",
            "------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 359         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 11          |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006053414 |\n",
            "|    clip_fraction        | 0.0709      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.26       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0168      |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.00478    |\n",
            "|    reward               | -0.09707139 |\n",
            "|    std                  | 0.998       |\n",
            "|    value_loss           | 0.171       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 343          |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 17           |\n",
            "|    total_timesteps      | 6144         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036903557 |\n",
            "|    clip_fraction        | 0.0205       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -4.26        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 4.45         |\n",
            "|    n_updates            | 20           |\n",
            "|    policy_gradient_loss | -0.00292     |\n",
            "|    reward               | 0.046608407  |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 9.54         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 348         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 23          |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006273346 |\n",
            "|    clip_fraction        | 0.0338      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.26       |\n",
            "|    explained_variance   | 0.0106      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 4.87        |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.00253    |\n",
            "|    reward               | 0.13062644  |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 9.99        |\n",
            "-----------------------------------------\n",
            "day: 2011, episode: 25\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1950860.47\n",
            "total_reward: 950860.47\n",
            "total_cost: 13567.53\n",
            "total_trades: 5932\n",
            "Sharpe: 0.863\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 340          |\n",
            "|    iterations           | 5            |\n",
            "|    time_elapsed         | 30           |\n",
            "|    total_timesteps      | 10240        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031413478 |\n",
            "|    clip_fraction        | 0.0115       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -4.27        |\n",
            "|    explained_variance   | 0.0428       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 6.56         |\n",
            "|    n_updates            | 40           |\n",
            "|    policy_gradient_loss | -0.00376     |\n",
            "|    reward               | -0.013481837 |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 15.3         |\n",
            "------------------------------------------\n",
            "======ppo Validation from:  2020-01-02 to  2020-04-02\n",
            "ppo Sharpe Ratio:  -0.2821199045435727\n",
            "======Best Model Retraining from:  2012-01-01 to  2020-04-02\n",
            "======Trading from:  2020-04-02 to  2020-07-02\n",
            "============================================\n",
            "turbulence_threshold:  24.528961738292235\n",
            "======Model training from:  2012-01-01 to  2020-04-02\n",
            "======a2c Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007, 'device': 'cuda'}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/a2c/a2c_441_1\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 295       |\n",
            "|    iterations         | 100       |\n",
            "|    time_elapsed       | 1         |\n",
            "|    total_timesteps    | 500       |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.28     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 99        |\n",
            "|    policy_loss        | -5.24     |\n",
            "|    reward             | -0.896401 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 2.18      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 298         |\n",
            "|    iterations         | 200         |\n",
            "|    time_elapsed       | 3           |\n",
            "|    total_timesteps    | 1000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.25       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 199         |\n",
            "|    policy_loss        | -20         |\n",
            "|    reward             | -0.17738517 |\n",
            "|    std                | 0.999       |\n",
            "|    value_loss         | 32          |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 298       |\n",
            "|    iterations         | 300       |\n",
            "|    time_elapsed       | 5         |\n",
            "|    total_timesteps    | 1500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.27     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 299       |\n",
            "|    policy_loss        | -3.49     |\n",
            "|    reward             | 1.7056105 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 6.01      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 300      |\n",
            "|    iterations         | 400      |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 2000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.27    |\n",
            "|    explained_variance | 5.96e-08 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 399      |\n",
            "|    policy_loss        | 18.3     |\n",
            "|    reward             | 5.021258 |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 49.7     |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 300        |\n",
            "|    iterations         | 500        |\n",
            "|    time_elapsed       | 8          |\n",
            "|    total_timesteps    | 2500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.26      |\n",
            "|    explained_variance | -2.5e-06   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 499        |\n",
            "|    policy_loss        | -3.31      |\n",
            "|    reward             | 0.35015306 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 1.04       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 283       |\n",
            "|    iterations         | 600       |\n",
            "|    time_elapsed       | 10        |\n",
            "|    total_timesteps    | 3000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.28     |\n",
            "|    explained_variance | 3.08e-05  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 599       |\n",
            "|    policy_loss        | 26.9      |\n",
            "|    reward             | 3.6361287 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 105       |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 280         |\n",
            "|    iterations         | 700         |\n",
            "|    time_elapsed       | 12          |\n",
            "|    total_timesteps    | 3500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.28       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 699         |\n",
            "|    policy_loss        | 10.5        |\n",
            "|    reward             | -0.21620895 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 6.88        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 282        |\n",
            "|    iterations         | 800        |\n",
            "|    time_elapsed       | 14         |\n",
            "|    total_timesteps    | 4000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.26      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 799        |\n",
            "|    policy_loss        | 37.5       |\n",
            "|    reward             | -5.0807867 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 91.7       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 284       |\n",
            "|    iterations         | 900       |\n",
            "|    time_elapsed       | 15        |\n",
            "|    total_timesteps    | 4500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.26     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 899       |\n",
            "|    policy_loss        | -2.2      |\n",
            "|    reward             | 1.4027531 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 1.68      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 285        |\n",
            "|    iterations         | 1000       |\n",
            "|    time_elapsed       | 17         |\n",
            "|    total_timesteps    | 5000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.23      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 999        |\n",
            "|    policy_loss        | 5.64       |\n",
            "|    reward             | 0.08462298 |\n",
            "|    std                | 0.992      |\n",
            "|    value_loss         | 3.51       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 286         |\n",
            "|    iterations         | 1100        |\n",
            "|    time_elapsed       | 19          |\n",
            "|    total_timesteps    | 5500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.23       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1099        |\n",
            "|    policy_loss        | 30.5        |\n",
            "|    reward             | -0.09427756 |\n",
            "|    std                | 0.991       |\n",
            "|    value_loss         | 77.2        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 288        |\n",
            "|    iterations         | 1200       |\n",
            "|    time_elapsed       | 20         |\n",
            "|    total_timesteps    | 6000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.22      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1199       |\n",
            "|    policy_loss        | -23.5      |\n",
            "|    reward             | -13.077177 |\n",
            "|    std                | 0.989      |\n",
            "|    value_loss         | 40         |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 283        |\n",
            "|    iterations         | 1300       |\n",
            "|    time_elapsed       | 22         |\n",
            "|    total_timesteps    | 6500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.21      |\n",
            "|    explained_variance | 0.125      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1299       |\n",
            "|    policy_loss        | 1.84       |\n",
            "|    reward             | 0.61227465 |\n",
            "|    std                | 0.986      |\n",
            "|    value_loss         | 0.62       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 280      |\n",
            "|    iterations         | 1400     |\n",
            "|    time_elapsed       | 24       |\n",
            "|    total_timesteps    | 7000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.23    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1399     |\n",
            "|    policy_loss        | -8.53    |\n",
            "|    reward             | 1.488107 |\n",
            "|    std                | 0.992    |\n",
            "|    value_loss         | 11.2     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 281      |\n",
            "|    iterations         | 1500     |\n",
            "|    time_elapsed       | 26       |\n",
            "|    total_timesteps    | 7500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.25    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1499     |\n",
            "|    policy_loss        | 4.84     |\n",
            "|    reward             | 1.306507 |\n",
            "|    std                | 0.999    |\n",
            "|    value_loss         | 1.45     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 282       |\n",
            "|    iterations         | 1600      |\n",
            "|    time_elapsed       | 28        |\n",
            "|    total_timesteps    | 8000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.26     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1599      |\n",
            "|    policy_loss        | 9.24      |\n",
            "|    reward             | 0.3345586 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 8.53      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 283       |\n",
            "|    iterations         | 1700      |\n",
            "|    time_elapsed       | 29        |\n",
            "|    total_timesteps    | 8500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.27     |\n",
            "|    explained_variance | 0.192     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1699      |\n",
            "|    policy_loss        | -7.75     |\n",
            "|    reward             | 0.7358769 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 5.39      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 284       |\n",
            "|    iterations         | 1800      |\n",
            "|    time_elapsed       | 31        |\n",
            "|    total_timesteps    | 9000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.27     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1799      |\n",
            "|    policy_loss        | -6.63     |\n",
            "|    reward             | -2.957783 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 3.73      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 285       |\n",
            "|    iterations         | 1900      |\n",
            "|    time_elapsed       | 33        |\n",
            "|    total_timesteps    | 9500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.29     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1899      |\n",
            "|    policy_loss        | -1.94     |\n",
            "|    reward             | 0.5918868 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 0.953     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 283        |\n",
            "|    iterations         | 2000       |\n",
            "|    time_elapsed       | 35         |\n",
            "|    total_timesteps    | 10000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.28      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1999       |\n",
            "|    policy_loss        | 19.1       |\n",
            "|    reward             | -0.5390279 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 19.9       |\n",
            "--------------------------------------\n",
            "======a2c Validation from:  2020-04-02 to  2020-07-02\n",
            "a2c Sharpe Ratio:  0.4096001116045794\n",
            "======ddpg Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64, 'device': 'cuda'}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ddpg/ddpg_441_1\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 4         |\n",
            "|    fps             | 121       |\n",
            "|    time_elapsed    | 68        |\n",
            "|    total_timesteps | 8300      |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -1.58e+03 |\n",
            "|    critic_loss     | 34.5      |\n",
            "|    learning_rate   | 0.0005    |\n",
            "|    n_updates       | 8199      |\n",
            "|    reward          | -12.31201 |\n",
            "----------------------------------\n",
            "======ddpg Validation from:  2020-04-02 to  2020-07-02\n",
            "ddpg Sharpe Ratio:  0.4478704320384481\n",
            "======td3 Training========\n",
            "{'device': 'cuda'}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/td3/td3_441_1\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 4         |\n",
            "|    fps             | 127       |\n",
            "|    time_elapsed    | 65        |\n",
            "|    total_timesteps | 8300      |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -1.12e+04 |\n",
            "|    critic_loss     | 1.02e+06  |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 8199      |\n",
            "|    reward          | 0.0       |\n",
            "----------------------------------\n",
            "======td3 Validation from:  2020-04-02 to  2020-07-02\n",
            "td3 Sharpe Ratio:  0.0\n",
            "======sac Training========\n",
            "{'device': 'cuda'}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/sac/sac_441_1\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 4        |\n",
            "|    fps             | 74       |\n",
            "|    time_elapsed    | 110      |\n",
            "|    total_timesteps | 8300     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 4.31e+04 |\n",
            "|    critic_loss     | 1.11e+05 |\n",
            "|    ent_coef        | 11.7     |\n",
            "|    ent_coef_loss   | -180     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 8199     |\n",
            "|    reward          | 0.0      |\n",
            "---------------------------------\n",
            "======sac Validation from:  2020-04-02 to  2020-07-02\n",
            "sac Sharpe Ratio:  0.0\n",
            "======ppo Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128, 'device': 'cuda'}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ppo/ppo_441_1\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    fps             | 338       |\n",
            "|    iterations      | 1         |\n",
            "|    time_elapsed    | 6         |\n",
            "|    total_timesteps | 2048      |\n",
            "| train/             |           |\n",
            "|    reward          | 2.7429876 |\n",
            "----------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 348         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 11          |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006688698 |\n",
            "|    clip_fraction        | 0.0554      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.25       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.567       |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.00304    |\n",
            "|    reward               | -2.849903   |\n",
            "|    std                  | 0.999       |\n",
            "|    value_loss           | 1.31        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 334         |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 18          |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004414842 |\n",
            "|    clip_fraction        | 0.0276      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.25       |\n",
            "|    explained_variance   | 0.0125      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 5.66        |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.00169    |\n",
            "|    reward               | 0.23434071  |\n",
            "|    std                  | 0.996       |\n",
            "|    value_loss           | 9.7         |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 340          |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 24           |\n",
            "|    total_timesteps      | 8192         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0043419125 |\n",
            "|    clip_fraction        | 0.0434       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -4.24        |\n",
            "|    explained_variance   | 0.0353       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 4.45         |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | -0.002       |\n",
            "|    reward               | 6.6178017    |\n",
            "|    std                  | 0.994        |\n",
            "|    value_loss           | 22.9         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 333          |\n",
            "|    iterations           | 5            |\n",
            "|    time_elapsed         | 30           |\n",
            "|    total_timesteps      | 10240        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035943978 |\n",
            "|    clip_fraction        | 0.0162       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -4.24        |\n",
            "|    explained_variance   | 0.0268       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 2.48         |\n",
            "|    n_updates            | 40           |\n",
            "|    policy_gradient_loss | -0.00257     |\n",
            "|    reward               | 2.6751502    |\n",
            "|    std                  | 0.996        |\n",
            "|    value_loss           | 36.2         |\n",
            "------------------------------------------\n",
            "======ppo Validation from:  2020-04-02 to  2020-07-02\n",
            "ppo Sharpe Ratio:  0.3896130825838506\n",
            "======Best Model Retraining from:  2012-01-01 to  2020-07-02\n",
            "======Trading from:  2020-07-02 to  2020-10-01\n",
            "============================================\n",
            "turbulence_threshold:  24.528961738292235\n",
            "======Model training from:  2012-01-01 to  2020-07-02\n",
            "======a2c Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007, 'device': 'cuda'}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/a2c/a2c_504_1\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 290         |\n",
            "|    iterations         | 100         |\n",
            "|    time_elapsed       | 1           |\n",
            "|    total_timesteps    | 500         |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.31       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 99          |\n",
            "|    policy_loss        | -0.787      |\n",
            "|    reward             | -0.11374923 |\n",
            "|    std                | 1.02        |\n",
            "|    value_loss         | 0.0431      |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 296         |\n",
            "|    iterations         | 200         |\n",
            "|    time_elapsed       | 3           |\n",
            "|    total_timesteps    | 1000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.33       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 199         |\n",
            "|    policy_loss        | -0.117      |\n",
            "|    reward             | -0.01043407 |\n",
            "|    std                | 1.02        |\n",
            "|    value_loss         | 0.000965    |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 294        |\n",
            "|    iterations         | 300        |\n",
            "|    time_elapsed       | 5          |\n",
            "|    total_timesteps    | 1500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.33      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 299        |\n",
            "|    policy_loss        | 3.73       |\n",
            "|    reward             | 0.27907124 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 0.697      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 293       |\n",
            "|    iterations         | 400       |\n",
            "|    time_elapsed       | 6         |\n",
            "|    total_timesteps    | 2000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.33     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 399       |\n",
            "|    policy_loss        | 2.19      |\n",
            "|    reward             | 1.3850051 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 0.571     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 282        |\n",
            "|    iterations         | 500        |\n",
            "|    time_elapsed       | 8          |\n",
            "|    total_timesteps    | 2500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.35      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 499        |\n",
            "|    policy_loss        | -1.15      |\n",
            "|    reward             | 0.17941704 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 0.293      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 269        |\n",
            "|    iterations         | 600        |\n",
            "|    time_elapsed       | 11         |\n",
            "|    total_timesteps    | 3000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.36      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 599        |\n",
            "|    policy_loss        | -0.501     |\n",
            "|    reward             | 0.52399457 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 0.0424     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 272        |\n",
            "|    iterations         | 700        |\n",
            "|    time_elapsed       | 12         |\n",
            "|    total_timesteps    | 3500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.36      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 699        |\n",
            "|    policy_loss        | -0.683     |\n",
            "|    reward             | -0.7031463 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 0.338      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 275        |\n",
            "|    iterations         | 800        |\n",
            "|    time_elapsed       | 14         |\n",
            "|    total_timesteps    | 4000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.35      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 799        |\n",
            "|    policy_loss        | -19.7      |\n",
            "|    reward             | 0.36171913 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 22.9       |\n",
            "--------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 277           |\n",
            "|    iterations         | 900           |\n",
            "|    time_elapsed       | 16            |\n",
            "|    total_timesteps    | 4500          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.37         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 899           |\n",
            "|    policy_loss        | -0.00595      |\n",
            "|    reward             | -0.0008275243 |\n",
            "|    std                | 1.04          |\n",
            "|    value_loss         | 0.00162       |\n",
            "-----------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 279       |\n",
            "|    iterations         | 1000      |\n",
            "|    time_elapsed       | 17        |\n",
            "|    total_timesteps    | 5000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.35     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 999       |\n",
            "|    policy_loss        | 2.26      |\n",
            "|    reward             | -0.377324 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 0.696     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 280        |\n",
            "|    iterations         | 1100       |\n",
            "|    time_elapsed       | 19         |\n",
            "|    total_timesteps    | 5500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.35      |\n",
            "|    explained_variance | 0.0097     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1099       |\n",
            "|    policy_loss        | -9.82      |\n",
            "|    reward             | -2.3611522 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 12.4       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 278       |\n",
            "|    iterations         | 1200      |\n",
            "|    time_elapsed       | 21        |\n",
            "|    total_timesteps    | 6000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.38     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1199      |\n",
            "|    policy_loss        | 21.9      |\n",
            "|    reward             | 1.9238101 |\n",
            "|    std                | 1.04      |\n",
            "|    value_loss         | 71.2      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 271         |\n",
            "|    iterations         | 1300        |\n",
            "|    time_elapsed       | 23          |\n",
            "|    total_timesteps    | 6500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.36       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1299        |\n",
            "|    policy_loss        | -0.215      |\n",
            "|    reward             | -0.00639202 |\n",
            "|    std                | 1.04        |\n",
            "|    value_loss         | 0.00404     |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 273        |\n",
            "|    iterations         | 1400       |\n",
            "|    time_elapsed       | 25         |\n",
            "|    total_timesteps    | 7000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.36      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1399       |\n",
            "|    policy_loss        | -5.35      |\n",
            "|    reward             | 0.07239586 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 0.628      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 274         |\n",
            "|    iterations         | 1500        |\n",
            "|    time_elapsed       | 27          |\n",
            "|    total_timesteps    | 7500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.36       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1499        |\n",
            "|    policy_loss        | -1.89       |\n",
            "|    reward             | -0.58360785 |\n",
            "|    std                | 1.04        |\n",
            "|    value_loss         | 0.495       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 275        |\n",
            "|    iterations         | 1600       |\n",
            "|    time_elapsed       | 29         |\n",
            "|    total_timesteps    | 8000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.36      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1599       |\n",
            "|    policy_loss        | -17.7      |\n",
            "|    reward             | -2.2805593 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 20         |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 277        |\n",
            "|    iterations         | 1700       |\n",
            "|    time_elapsed       | 30         |\n",
            "|    total_timesteps    | 8500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.38      |\n",
            "|    explained_variance | 0.062      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1699       |\n",
            "|    policy_loss        | 107        |\n",
            "|    reward             | -16.292215 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 559        |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 277       |\n",
            "|    iterations         | 1800      |\n",
            "|    time_elapsed       | 32        |\n",
            "|    total_timesteps    | 9000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.38     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1799      |\n",
            "|    policy_loss        | 0.864     |\n",
            "|    reward             | 2.2156491 |\n",
            "|    std                | 1.04      |\n",
            "|    value_loss         | 1.98      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 276        |\n",
            "|    iterations         | 1900       |\n",
            "|    time_elapsed       | 34         |\n",
            "|    total_timesteps    | 9500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.36      |\n",
            "|    explained_variance | 0.00558    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1899       |\n",
            "|    policy_loss        | -28.1      |\n",
            "|    reward             | -2.8721151 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 68.7       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 273      |\n",
            "|    iterations         | 2000     |\n",
            "|    time_elapsed       | 36       |\n",
            "|    total_timesteps    | 10000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.37    |\n",
            "|    explained_variance | -0.089   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1999     |\n",
            "|    policy_loss        | -19      |\n",
            "|    reward             | 4.633966 |\n",
            "|    std                | 1.04     |\n",
            "|    value_loss         | 54.2     |\n",
            "------------------------------------\n",
            "======a2c Validation from:  2020-07-02 to  2020-10-01\n",
            "a2c Sharpe Ratio:  0.21741883659764574\n",
            "======ddpg Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64, 'device': 'cuda'}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ddpg/ddpg_504_1\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 4        |\n",
            "|    fps             | 120      |\n",
            "|    time_elapsed    | 70       |\n",
            "|    total_timesteps | 8552     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 5.41e+03 |\n",
            "|    critic_loss     | 4.78e+04 |\n",
            "|    learning_rate   | 0.0005   |\n",
            "|    n_updates       | 8451     |\n",
            "|    reward          | 0.0      |\n",
            "---------------------------------\n",
            "======ddpg Validation from:  2020-07-02 to  2020-10-01\n",
            "ddpg Sharpe Ratio:  0.0\n",
            "======td3 Training========\n",
            "{'device': 'cuda'}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/td3/td3_504_1\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 4         |\n",
            "|    fps             | 127       |\n",
            "|    time_elapsed    | 67        |\n",
            "|    total_timesteps | 8552      |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 4.95e+03  |\n",
            "|    critic_loss     | 1.01e+03  |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 8451      |\n",
            "|    reward          | 6.7115273 |\n",
            "----------------------------------\n",
            "======td3 Validation from:  2020-07-02 to  2020-10-01\n",
            "td3 Sharpe Ratio:  0.2863152915853514\n",
            "======sac Training========\n",
            "{'device': 'cuda'}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/sac/sac_504_1\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 4         |\n",
            "|    fps             | 74        |\n",
            "|    time_elapsed    | 114       |\n",
            "|    total_timesteps | 8552      |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 1.18e+04  |\n",
            "|    critic_loss     | 2.16e+03  |\n",
            "|    ent_coef        | 11.9      |\n",
            "|    ent_coef_loss   | -147      |\n",
            "|    learning_rate   | 0.0003    |\n",
            "|    n_updates       | 8451      |\n",
            "|    reward          | 28.236393 |\n",
            "----------------------------------\n",
            "======sac Validation from:  2020-07-02 to  2020-10-01\n",
            "sac Sharpe Ratio:  0.292272008322882\n",
            "======ppo Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128, 'device': 'cuda'}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ppo/ppo_504_1\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    fps             | 410       |\n",
            "|    iterations      | 1         |\n",
            "|    time_elapsed    | 4         |\n",
            "|    total_timesteps | 2048      |\n",
            "| train/             |           |\n",
            "|    reward          | 1.9411811 |\n",
            "----------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 362          |\n",
            "|    iterations           | 2            |\n",
            "|    time_elapsed         | 11           |\n",
            "|    total_timesteps      | 4096         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0046890723 |\n",
            "|    clip_fraction        | 0.0392       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -4.26        |\n",
            "|    explained_variance   | -0.00774     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.841        |\n",
            "|    n_updates            | 10           |\n",
            "|    policy_gradient_loss | -0.00163     |\n",
            "|    reward               | 0.23828472   |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.96         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 357         |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 17          |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005053913 |\n",
            "|    clip_fraction        | 0.0315      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.26       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 1.01        |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.00215    |\n",
            "|    reward               | 1.4583378   |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 3.7         |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 350          |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 23           |\n",
            "|    total_timesteps      | 8192         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0041133217 |\n",
            "|    clip_fraction        | 0.0257       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -4.26        |\n",
            "|    explained_variance   | 0.00103      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 4.23         |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | -0.00131     |\n",
            "|    reward               | 0.19665141   |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 6.09         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 346          |\n",
            "|    iterations           | 5            |\n",
            "|    time_elapsed         | 29           |\n",
            "|    total_timesteps      | 10240        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0055872845 |\n",
            "|    clip_fraction        | 0.0281       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -4.25        |\n",
            "|    explained_variance   | -2.36e-05    |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 4.78         |\n",
            "|    n_updates            | 40           |\n",
            "|    policy_gradient_loss | -0.000899    |\n",
            "|    reward               | -1.4917933   |\n",
            "|    std                  | 0.996        |\n",
            "|    value_loss           | 8.48         |\n",
            "------------------------------------------\n",
            "======ppo Validation from:  2020-07-02 to  2020-10-01\n",
            "ppo Sharpe Ratio:  0.07324867950183737\n",
            "======Best Model Retraining from:  2012-01-01 to  2020-10-01\n",
            "======Trading from:  2020-10-01 to  2020-12-31\n",
            "============================================\n",
            "turbulence_threshold:  24.528961738292235\n",
            "======Model training from:  2012-01-01 to  2020-10-01\n",
            "======a2c Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007, 'device': 'cuda'}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/a2c/a2c_567_1\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 289         |\n",
            "|    iterations         | 100         |\n",
            "|    time_elapsed       | 1           |\n",
            "|    total_timesteps    | 500         |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.29       |\n",
            "|    explained_variance | 0.292       |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 99          |\n",
            "|    policy_loss        | -3.02       |\n",
            "|    reward             | -0.60422474 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 0.797       |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 287       |\n",
            "|    iterations         | 200       |\n",
            "|    time_elapsed       | 3         |\n",
            "|    total_timesteps    | 1000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.29     |\n",
            "|    explained_variance | 0.0236    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 199       |\n",
            "|    policy_loss        | -13.8     |\n",
            "|    reward             | 0.0216516 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 19.3      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 266       |\n",
            "|    iterations         | 300       |\n",
            "|    time_elapsed       | 5         |\n",
            "|    total_timesteps    | 1500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.27     |\n",
            "|    explained_variance | 0.0251    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 299       |\n",
            "|    policy_loss        | -1.88     |\n",
            "|    reward             | 1.5465289 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 4.81      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 257      |\n",
            "|    iterations         | 400      |\n",
            "|    time_elapsed       | 7        |\n",
            "|    total_timesteps    | 2000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.28    |\n",
            "|    explained_variance | -0.00197 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 399      |\n",
            "|    policy_loss        | 18       |\n",
            "|    reward             | 4.523959 |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 40       |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 264        |\n",
            "|    iterations         | 500        |\n",
            "|    time_elapsed       | 9          |\n",
            "|    total_timesteps    | 2500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.27      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 499        |\n",
            "|    policy_loss        | -3.61      |\n",
            "|    reward             | 0.48248762 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 1.26       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 268       |\n",
            "|    iterations         | 600       |\n",
            "|    time_elapsed       | 11        |\n",
            "|    total_timesteps    | 3000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.27     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 599       |\n",
            "|    policy_loss        | -7.62     |\n",
            "|    reward             | -2.055509 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 9.73      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 271        |\n",
            "|    iterations         | 700        |\n",
            "|    time_elapsed       | 12         |\n",
            "|    total_timesteps    | 3500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.27      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 699        |\n",
            "|    policy_loss        | -4.44      |\n",
            "|    reward             | -1.6499166 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 1.2        |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 273       |\n",
            "|    iterations         | 800       |\n",
            "|    time_elapsed       | 14        |\n",
            "|    total_timesteps    | 4000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.27     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 799       |\n",
            "|    policy_loss        | 5.85      |\n",
            "|    reward             | 1.5011094 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 2.76      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 275        |\n",
            "|    iterations         | 900        |\n",
            "|    time_elapsed       | 16         |\n",
            "|    total_timesteps    | 4500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.26      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 899        |\n",
            "|    policy_loss        | -1.8       |\n",
            "|    reward             | -0.5123604 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 0.331      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 271         |\n",
            "|    iterations         | 1000        |\n",
            "|    time_elapsed       | 18          |\n",
            "|    total_timesteps    | 5000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.24       |\n",
            "|    explained_variance | 0.0128      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 999         |\n",
            "|    policy_loss        | 1.71        |\n",
            "|    reward             | -0.04040276 |\n",
            "|    std                | 0.996       |\n",
            "|    value_loss         | 0.543       |\n",
            "---------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 265      |\n",
            "|    iterations         | 1100     |\n",
            "|    time_elapsed       | 20       |\n",
            "|    total_timesteps    | 5500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.24    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1099     |\n",
            "|    policy_loss        | -9.83    |\n",
            "|    reward             | 3.3028   |\n",
            "|    std                | 0.995    |\n",
            "|    value_loss         | 4.18     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 267       |\n",
            "|    iterations         | 1200      |\n",
            "|    time_elapsed       | 22        |\n",
            "|    total_timesteps    | 6000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.25     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1199      |\n",
            "|    policy_loss        | 54.5      |\n",
            "|    reward             | 1.6441668 |\n",
            "|    std                | 0.997     |\n",
            "|    value_loss         | 198       |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 269       |\n",
            "|    iterations         | 1300      |\n",
            "|    time_elapsed       | 24        |\n",
            "|    total_timesteps    | 6500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.25     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1299      |\n",
            "|    policy_loss        | 27.5      |\n",
            "|    reward             | 7.4596868 |\n",
            "|    std                | 0.998     |\n",
            "|    value_loss         | 92.7      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 271         |\n",
            "|    iterations         | 1400        |\n",
            "|    time_elapsed       | 25          |\n",
            "|    total_timesteps    | 7000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.25       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1399        |\n",
            "|    policy_loss        | -0.287      |\n",
            "|    reward             | 0.119728126 |\n",
            "|    std                | 0.998       |\n",
            "|    value_loss         | 0.415       |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 272         |\n",
            "|    iterations         | 1500        |\n",
            "|    time_elapsed       | 27          |\n",
            "|    total_timesteps    | 7500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.27       |\n",
            "|    explained_variance | 1.79e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1499        |\n",
            "|    policy_loss        | -51.4       |\n",
            "|    reward             | -0.30596378 |\n",
            "|    std                | 1           |\n",
            "|    value_loss         | 107         |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 273        |\n",
            "|    iterations         | 1600       |\n",
            "|    time_elapsed       | 29         |\n",
            "|    total_timesteps    | 8000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.29      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1599       |\n",
            "|    policy_loss        | 15.7       |\n",
            "|    reward             | 0.78205466 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 17.1       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 272       |\n",
            "|    iterations         | 1700      |\n",
            "|    time_elapsed       | 31        |\n",
            "|    total_timesteps    | 8500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.26     |\n",
            "|    explained_variance | 0.00307   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1699      |\n",
            "|    policy_loss        | 3.16      |\n",
            "|    reward             | 2.3791249 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 4.77      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 267        |\n",
            "|    iterations         | 1800       |\n",
            "|    time_elapsed       | 33         |\n",
            "|    total_timesteps    | 9000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.25      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1799       |\n",
            "|    policy_loss        | 0.623      |\n",
            "|    reward             | 0.39583892 |\n",
            "|    std                | 0.997      |\n",
            "|    value_loss         | 0.229      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 269       |\n",
            "|    iterations         | 1900      |\n",
            "|    time_elapsed       | 35        |\n",
            "|    total_timesteps    | 9500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.25     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1899      |\n",
            "|    policy_loss        | -4.2      |\n",
            "|    reward             | 3.6690233 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 3.16      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 270        |\n",
            "|    iterations         | 2000       |\n",
            "|    time_elapsed       | 36         |\n",
            "|    total_timesteps    | 10000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.26      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1999       |\n",
            "|    policy_loss        | -6.07      |\n",
            "|    reward             | 0.38650772 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 3.59       |\n",
            "--------------------------------------\n",
            "======a2c Validation from:  2020-10-01 to  2020-12-31\n",
            "a2c Sharpe Ratio:  0.3076940362029842\n",
            "======ddpg Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64, 'device': 'cuda'}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ddpg/ddpg_567_1\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 4        |\n",
            "|    fps             | 117      |\n",
            "|    time_elapsed    | 74       |\n",
            "|    total_timesteps | 8804     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 1.49e+03 |\n",
            "|    critic_loss     | 54.2     |\n",
            "|    learning_rate   | 0.0005   |\n",
            "|    n_updates       | 8703     |\n",
            "|    reward          | 4.500876 |\n",
            "---------------------------------\n",
            "======ddpg Validation from:  2020-10-01 to  2020-12-31\n",
            "ddpg Sharpe Ratio:  0.47835286535187677\n",
            "======td3 Training========\n",
            "{'device': 'cuda'}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/td3/td3_567_1\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 4         |\n",
            "|    fps             | 126       |\n",
            "|    time_elapsed    | 69        |\n",
            "|    total_timesteps | 8804      |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -4.82e+03 |\n",
            "|    critic_loss     | 1.66e+03  |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 8703      |\n",
            "|    reward          | 17.962421 |\n",
            "----------------------------------\n",
            "======td3 Validation from:  2020-10-01 to  2020-12-31\n",
            "td3 Sharpe Ratio:  0.40334497736343616\n",
            "======sac Training========\n",
            "{'device': 'cuda'}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/sac/sac_567_1\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 4         |\n",
            "|    fps             | 74        |\n",
            "|    time_elapsed    | 118       |\n",
            "|    total_timesteps | 8804      |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 4.95e+03  |\n",
            "|    critic_loss     | 1.07e+03  |\n",
            "|    ent_coef        | 12.3      |\n",
            "|    ent_coef_loss   | -70.6     |\n",
            "|    learning_rate   | 0.0003    |\n",
            "|    n_updates       | 8703      |\n",
            "|    reward          | 17.962421 |\n",
            "----------------------------------\n",
            "======sac Validation from:  2020-10-01 to  2020-12-31\n",
            "sac Sharpe Ratio:  0.40334497736343616\n",
            "======ppo Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128, 'device': 'cuda'}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ppo/ppo_567_1\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    fps             | 385        |\n",
            "|    iterations      | 1          |\n",
            "|    time_elapsed    | 5          |\n",
            "|    total_timesteps | 2048       |\n",
            "| train/             |            |\n",
            "|    reward          | 0.78975064 |\n",
            "-----------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 353          |\n",
            "|    iterations           | 2            |\n",
            "|    time_elapsed         | 11           |\n",
            "|    total_timesteps      | 4096         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0042402684 |\n",
            "|    clip_fraction        | 0.033        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -4.25        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.414        |\n",
            "|    n_updates            | 10           |\n",
            "|    policy_gradient_loss | -0.00188     |\n",
            "|    reward               | -1.4932288   |\n",
            "|    std                  | 0.993        |\n",
            "|    value_loss           | 0.979        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 352          |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 17           |\n",
            "|    total_timesteps      | 6144         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029306398 |\n",
            "|    clip_fraction        | 0.0157       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -4.24        |\n",
            "|    explained_variance   | -0.0076      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 5.26         |\n",
            "|    n_updates            | 20           |\n",
            "|    policy_gradient_loss | -0.00264     |\n",
            "|    reward               | -1.7336318   |\n",
            "|    std                  | 0.997        |\n",
            "|    value_loss           | 8.07         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 341          |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 23           |\n",
            "|    total_timesteps      | 8192         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0043807696 |\n",
            "|    clip_fraction        | 0.0128       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -4.25        |\n",
            "|    explained_variance   | -0.041       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 18.5         |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | -0.00278     |\n",
            "|    reward               | 4.4294896    |\n",
            "|    std                  | 0.997        |\n",
            "|    value_loss           | 38.9         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 345          |\n",
            "|    iterations           | 5            |\n",
            "|    time_elapsed         | 29           |\n",
            "|    total_timesteps      | 10240        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033918803 |\n",
            "|    clip_fraction        | 0.0114       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -4.25        |\n",
            "|    explained_variance   | 0.0935       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 29.4         |\n",
            "|    n_updates            | 40           |\n",
            "|    policy_gradient_loss | -0.00292     |\n",
            "|    reward               | 0.86548615   |\n",
            "|    std                  | 0.998        |\n",
            "|    value_loss           | 33.8         |\n",
            "------------------------------------------\n",
            "======ppo Validation from:  2020-10-01 to  2020-12-31\n",
            "ppo Sharpe Ratio:  0.31301278294378837\n",
            "======Best Model Retraining from:  2012-01-01 to  2020-12-31\n",
            "======Trading from:  2020-12-31 to  2021-04-05\n",
            "============================================\n",
            "turbulence_threshold:  24.528961738292235\n",
            "======Model training from:  2012-01-01 to  2020-12-31\n",
            "======a2c Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007, 'device': 'cuda'}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/a2c/a2c_630_1\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 205        |\n",
            "|    iterations         | 100        |\n",
            "|    time_elapsed       | 2          |\n",
            "|    total_timesteps    | 500        |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.23      |\n",
            "|    explained_variance | 0.038      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 99         |\n",
            "|    policy_loss        | -5.05      |\n",
            "|    reward             | -0.8354404 |\n",
            "|    std                | 0.992      |\n",
            "|    value_loss         | 2.32       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 242       |\n",
            "|    iterations         | 200       |\n",
            "|    time_elapsed       | 4         |\n",
            "|    total_timesteps    | 1000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.25     |\n",
            "|    explained_variance | -2.38e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 199       |\n",
            "|    policy_loss        | 3.64      |\n",
            "|    reward             | 2.1227553 |\n",
            "|    std                | 0.996     |\n",
            "|    value_loss         | 3.31      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 256       |\n",
            "|    iterations         | 300       |\n",
            "|    time_elapsed       | 5         |\n",
            "|    total_timesteps    | 1500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.23     |\n",
            "|    explained_variance | 0.0565    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 299       |\n",
            "|    policy_loss        | 16.3      |\n",
            "|    reward             | 5.4069386 |\n",
            "|    std                | 0.992     |\n",
            "|    value_loss         | 34        |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 264       |\n",
            "|    iterations         | 400       |\n",
            "|    time_elapsed       | 7         |\n",
            "|    total_timesteps    | 2000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.24     |\n",
            "|    explained_variance | 0.0582    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 399       |\n",
            "|    policy_loss        | 5.26      |\n",
            "|    reward             | 3.9540818 |\n",
            "|    std                | 0.996     |\n",
            "|    value_loss         | 25.2      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 270        |\n",
            "|    iterations         | 500        |\n",
            "|    time_elapsed       | 9          |\n",
            "|    total_timesteps    | 2500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.26      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 499        |\n",
            "|    policy_loss        | -0.849     |\n",
            "|    reward             | 0.19338231 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 0.0455     |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 274         |\n",
            "|    iterations         | 600         |\n",
            "|    time_elapsed       | 10          |\n",
            "|    total_timesteps    | 3000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.29       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 599         |\n",
            "|    policy_loss        | -0.0383     |\n",
            "|    reward             | 0.009007345 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 0.000233    |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 273       |\n",
            "|    iterations         | 700       |\n",
            "|    time_elapsed       | 12        |\n",
            "|    total_timesteps    | 3500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.32     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 699       |\n",
            "|    policy_loss        | 0.616     |\n",
            "|    reward             | 0.0222577 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 0.0254    |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 262       |\n",
            "|    iterations         | 800       |\n",
            "|    time_elapsed       | 15        |\n",
            "|    total_timesteps    | 4000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.34     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 799       |\n",
            "|    policy_loss        | -1.39     |\n",
            "|    reward             | 0.5531089 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 0.318     |\n",
            "-------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 265          |\n",
            "|    iterations         | 900          |\n",
            "|    time_elapsed       | 16           |\n",
            "|    total_timesteps    | 4500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.35        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 899          |\n",
            "|    policy_loss        | -0.268       |\n",
            "|    reward             | -0.005829894 |\n",
            "|    std                | 1.03         |\n",
            "|    value_loss         | 0.00414      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 267          |\n",
            "|    iterations         | 1000         |\n",
            "|    time_elapsed       | 18           |\n",
            "|    total_timesteps    | 5000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.38        |\n",
            "|    explained_variance | 1.19e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 999          |\n",
            "|    policy_loss        | 0.128        |\n",
            "|    reward             | -0.036371525 |\n",
            "|    std                | 1.04         |\n",
            "|    value_loss         | 0.00093      |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 269         |\n",
            "|    iterations         | 1100        |\n",
            "|    time_elapsed       | 20          |\n",
            "|    total_timesteps    | 5500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.41       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1099        |\n",
            "|    policy_loss        | 3.81        |\n",
            "|    reward             | -0.19995703 |\n",
            "|    std                | 1.05        |\n",
            "|    value_loss         | 1.21        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 271       |\n",
            "|    iterations         | 1200      |\n",
            "|    time_elapsed       | 22        |\n",
            "|    total_timesteps    | 6000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.39     |\n",
            "|    explained_variance | 0.0203    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1199      |\n",
            "|    policy_loss        | 31.4      |\n",
            "|    reward             | 1.1295476 |\n",
            "|    std                | 1.05      |\n",
            "|    value_loss         | 69.2      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 272       |\n",
            "|    iterations         | 1300      |\n",
            "|    time_elapsed       | 23        |\n",
            "|    total_timesteps    | 6500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.39     |\n",
            "|    explained_variance | 0.0498    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1299      |\n",
            "|    policy_loss        | 65.9      |\n",
            "|    reward             | 1.1223269 |\n",
            "|    std                | 1.05      |\n",
            "|    value_loss         | 123       |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 273       |\n",
            "|    iterations         | 1400      |\n",
            "|    time_elapsed       | 25        |\n",
            "|    total_timesteps    | 7000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.39     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1399      |\n",
            "|    policy_loss        | -4.73     |\n",
            "|    reward             | 1.1679504 |\n",
            "|    std                | 1.05      |\n",
            "|    value_loss         | 1.14      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 267        |\n",
            "|    iterations         | 1500       |\n",
            "|    time_elapsed       | 28         |\n",
            "|    total_timesteps    | 7500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.37      |\n",
            "|    explained_variance | 0.00654    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1499       |\n",
            "|    policy_loss        | -4.47      |\n",
            "|    reward             | -3.7066023 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 4.12       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 267        |\n",
            "|    iterations         | 1600       |\n",
            "|    time_elapsed       | 29         |\n",
            "|    total_timesteps    | 8000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.36      |\n",
            "|    explained_variance | 0.00854    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1599       |\n",
            "|    policy_loss        | -12.7      |\n",
            "|    reward             | 0.09940995 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 13.7       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 268      |\n",
            "|    iterations         | 1700     |\n",
            "|    time_elapsed       | 31       |\n",
            "|    total_timesteps    | 8500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.36    |\n",
            "|    explained_variance | 0.00143  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1699     |\n",
            "|    policy_loss        | -34.4    |\n",
            "|    reward             | 2.086236 |\n",
            "|    std                | 1.04     |\n",
            "|    value_loss         | 114      |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 269      |\n",
            "|    iterations         | 1800     |\n",
            "|    time_elapsed       | 33       |\n",
            "|    total_timesteps    | 9000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.35    |\n",
            "|    explained_variance | -0.0182  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1799     |\n",
            "|    policy_loss        | -42.9    |\n",
            "|    reward             | 25.00779 |\n",
            "|    std                | 1.03     |\n",
            "|    value_loss         | 130      |\n",
            "------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 271         |\n",
            "|    iterations         | 1900        |\n",
            "|    time_elapsed       | 35          |\n",
            "|    total_timesteps    | 9500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.35       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1899        |\n",
            "|    policy_loss        | 4.39        |\n",
            "|    reward             | -0.79329574 |\n",
            "|    std                | 1.03        |\n",
            "|    value_loss         | 2.22        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 271       |\n",
            "|    iterations         | 2000      |\n",
            "|    time_elapsed       | 36        |\n",
            "|    total_timesteps    | 10000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.37     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1999      |\n",
            "|    policy_loss        | -1.08     |\n",
            "|    reward             | 4.8880343 |\n",
            "|    std                | 1.04      |\n",
            "|    value_loss         | 1.55      |\n",
            "-------------------------------------\n",
            "======a2c Validation from:  2020-12-31 to  2021-04-05\n",
            "a2c Sharpe Ratio:  0.09575644658085847\n",
            "======ddpg Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64, 'device': 'cuda'}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ddpg/ddpg_630_1\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 4         |\n",
            "|    fps             | 117       |\n",
            "|    time_elapsed    | 76        |\n",
            "|    total_timesteps | 9056      |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -1.64e+04 |\n",
            "|    critic_loss     | 1.6e+05   |\n",
            "|    learning_rate   | 0.0005    |\n",
            "|    n_updates       | 8955      |\n",
            "|    reward          | 0.0       |\n",
            "----------------------------------\n",
            "======ddpg Validation from:  2020-12-31 to  2021-04-05\n",
            "ddpg Sharpe Ratio:  0.0\n",
            "======td3 Training========\n",
            "{'device': 'cuda'}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/td3/td3_630_1\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 4         |\n",
            "|    fps             | 129       |\n",
            "|    time_elapsed    | 70        |\n",
            "|    total_timesteps | 9056      |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 1.43e+03  |\n",
            "|    critic_loss     | 786       |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 8955      |\n",
            "|    reward          | 0.2536452 |\n",
            "----------------------------------\n",
            "======td3 Validation from:  2020-12-31 to  2021-04-05\n",
            "td3 Sharpe Ratio:  -0.05219706039117636\n",
            "======sac Training========\n",
            "{'device': 'cuda'}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/sac/sac_630_1\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 4        |\n",
            "|    fps             | 74       |\n",
            "|    time_elapsed    | 120      |\n",
            "|    total_timesteps | 9056     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 3.42e+04 |\n",
            "|    critic_loss     | 5.84e+05 |\n",
            "|    ent_coef        | 14.7     |\n",
            "|    ent_coef_loss   | -136     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 8955     |\n",
            "|    reward          | 0.0      |\n",
            "---------------------------------\n",
            "======sac Validation from:  2020-12-31 to  2021-04-05\n",
            "sac Sharpe Ratio:  0.0\n",
            "======ppo Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128, 'device': 'cuda'}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ppo/ppo_630_1\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    fps             | 338       |\n",
            "|    iterations      | 1         |\n",
            "|    time_elapsed    | 6         |\n",
            "|    total_timesteps | 2048      |\n",
            "| train/             |           |\n",
            "|    reward          | 0.8931373 |\n",
            "----------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 346          |\n",
            "|    iterations           | 2            |\n",
            "|    time_elapsed         | 11           |\n",
            "|    total_timesteps      | 4096         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0042579747 |\n",
            "|    clip_fraction        | 0.0201       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -4.27        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.09         |\n",
            "|    n_updates            | 10           |\n",
            "|    policy_gradient_loss | -0.000275    |\n",
            "|    reward               | 0.1321071    |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 2.5          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 337          |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 18           |\n",
            "|    total_timesteps      | 6144         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0067915358 |\n",
            "|    clip_fraction        | 0.0474       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -4.28        |\n",
            "|    explained_variance   | 1.19e-07     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 8.83         |\n",
            "|    n_updates            | 20           |\n",
            "|    policy_gradient_loss | -0.00209     |\n",
            "|    reward               | 0.10815225   |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 21           |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 338          |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 24           |\n",
            "|    total_timesteps      | 8192         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0061246613 |\n",
            "|    clip_fraction        | 0.0583       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -4.28        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.637        |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | -0.00369     |\n",
            "|    reward               | 0.31958348   |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 1.46         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 329          |\n",
            "|    iterations           | 5            |\n",
            "|    time_elapsed         | 31           |\n",
            "|    total_timesteps      | 10240        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0041166027 |\n",
            "|    clip_fraction        | 0.0203       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -4.28        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 5.88         |\n",
            "|    n_updates            | 40           |\n",
            "|    policy_gradient_loss | -0.00189     |\n",
            "|    reward               | 0.1978713    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 12.3         |\n",
            "------------------------------------------\n",
            "======ppo Validation from:  2020-12-31 to  2021-04-05\n",
            "ppo Sharpe Ratio:  0.02521568064040961\n",
            "======Best Model Retraining from:  2012-01-01 to  2021-04-05\n",
            "======Trading from:  2021-04-05 to  2021-07-02\n",
            "============================================\n",
            "turbulence_threshold:  24.528961738292235\n",
            "======Model training from:  2012-01-01 to  2021-04-05\n",
            "======a2c Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007, 'device': 'cuda'}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/a2c/a2c_693_1\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 247        |\n",
            "|    iterations         | 100        |\n",
            "|    time_elapsed       | 2          |\n",
            "|    total_timesteps    | 500        |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.28      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 99         |\n",
            "|    policy_loss        | -7.41      |\n",
            "|    reward             | -1.2059048 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 4.75       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 268       |\n",
            "|    iterations         | 200       |\n",
            "|    time_elapsed       | 3         |\n",
            "|    total_timesteps    | 1000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.29     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 199       |\n",
            "|    policy_loss        | -10.6     |\n",
            "|    reward             | 0.8345211 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 9.71      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 277       |\n",
            "|    iterations         | 300       |\n",
            "|    time_elapsed       | 5         |\n",
            "|    total_timesteps    | 1500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.3      |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 299       |\n",
            "|    policy_loss        | 5.9       |\n",
            "|    reward             | 3.2964559 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 9.59      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 282      |\n",
            "|    iterations         | 400      |\n",
            "|    time_elapsed       | 7        |\n",
            "|    total_timesteps    | 2000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.3     |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 399      |\n",
            "|    policy_loss        | 24.8     |\n",
            "|    reward             | 4.889376 |\n",
            "|    std                | 1.02     |\n",
            "|    value_loss         | 41.9     |\n",
            "------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 284         |\n",
            "|    iterations         | 500         |\n",
            "|    time_elapsed       | 8           |\n",
            "|    total_timesteps    | 2500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.29       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 499         |\n",
            "|    policy_loss        | -0.83       |\n",
            "|    reward             | -0.20804413 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 0.675       |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 285       |\n",
            "|    iterations         | 600       |\n",
            "|    time_elapsed       | 10        |\n",
            "|    total_timesteps    | 3000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.3      |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 599       |\n",
            "|    policy_loss        | 2.03      |\n",
            "|    reward             | 2.0504777 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 0.591     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 275        |\n",
            "|    iterations         | 700        |\n",
            "|    time_elapsed       | 12         |\n",
            "|    total_timesteps    | 3500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.27      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 699        |\n",
            "|    policy_loss        | 0.0879     |\n",
            "|    reward             | -0.7275391 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 0.0593     |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 272      |\n",
            "|    iterations         | 800      |\n",
            "|    time_elapsed       | 14       |\n",
            "|    total_timesteps    | 4000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.28    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 799      |\n",
            "|    policy_loss        | 4.39     |\n",
            "|    reward             | 3.507294 |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 2.14     |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 274        |\n",
            "|    iterations         | 900        |\n",
            "|    time_elapsed       | 16         |\n",
            "|    total_timesteps    | 4500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.28      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 899        |\n",
            "|    policy_loss        | 4.7        |\n",
            "|    reward             | 15.1691065 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 78.3       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 276       |\n",
            "|    iterations         | 1000      |\n",
            "|    time_elapsed       | 18        |\n",
            "|    total_timesteps    | 5000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.28     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 999       |\n",
            "|    policy_loss        | -5.8      |\n",
            "|    reward             | 1.1646188 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 2.12      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 277       |\n",
            "|    iterations         | 1100      |\n",
            "|    time_elapsed       | 19        |\n",
            "|    total_timesteps    | 5500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.26     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1099      |\n",
            "|    policy_loss        | -3.25     |\n",
            "|    reward             | 2.4900157 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 6.42      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 279        |\n",
            "|    iterations         | 1200       |\n",
            "|    time_elapsed       | 21         |\n",
            "|    total_timesteps    | 6000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.26      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1199       |\n",
            "|    policy_loss        | 6.34       |\n",
            "|    reward             | 0.22464064 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 4.52       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 280       |\n",
            "|    iterations         | 1300      |\n",
            "|    time_elapsed       | 23        |\n",
            "|    total_timesteps    | 6500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.26     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1299      |\n",
            "|    policy_loss        | 19.2      |\n",
            "|    reward             | 0.5113004 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 53.5      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 275        |\n",
            "|    iterations         | 1400       |\n",
            "|    time_elapsed       | 25         |\n",
            "|    total_timesteps    | 7000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.28      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1399       |\n",
            "|    policy_loss        | 0.063      |\n",
            "|    reward             | 0.18993114 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 0.000854   |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 273        |\n",
            "|    iterations         | 1500       |\n",
            "|    time_elapsed       | 27         |\n",
            "|    total_timesteps    | 7500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.28      |\n",
            "|    explained_variance | 5.96e-08   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1499       |\n",
            "|    policy_loss        | 4.22       |\n",
            "|    reward             | -4.0228357 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 4.59       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 275       |\n",
            "|    iterations         | 1600      |\n",
            "|    time_elapsed       | 29        |\n",
            "|    total_timesteps    | 8000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.25     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1599      |\n",
            "|    policy_loss        | -10.6     |\n",
            "|    reward             | 1.4995515 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 9.09      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 276       |\n",
            "|    iterations         | 1700      |\n",
            "|    time_elapsed       | 30        |\n",
            "|    total_timesteps    | 8500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.23     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1699      |\n",
            "|    policy_loss        | 18.5      |\n",
            "|    reward             | -2.962506 |\n",
            "|    std                | 0.993     |\n",
            "|    value_loss         | 22.3      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 277        |\n",
            "|    iterations         | 1800       |\n",
            "|    time_elapsed       | 32         |\n",
            "|    total_timesteps    | 9000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.23      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1799       |\n",
            "|    policy_loss        | -11        |\n",
            "|    reward             | -2.0937047 |\n",
            "|    std                | 0.993      |\n",
            "|    value_loss         | 16.7       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 278        |\n",
            "|    iterations         | 1900       |\n",
            "|    time_elapsed       | 34         |\n",
            "|    total_timesteps    | 9500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.25      |\n",
            "|    explained_variance | 0.181      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1899       |\n",
            "|    policy_loss        | -6.67      |\n",
            "|    reward             | 0.08686656 |\n",
            "|    std                | 0.998      |\n",
            "|    value_loss         | 4.14       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 279        |\n",
            "|    iterations         | 2000       |\n",
            "|    time_elapsed       | 35         |\n",
            "|    total_timesteps    | 10000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.25      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1999       |\n",
            "|    policy_loss        | -14.8      |\n",
            "|    reward             | 0.37719128 |\n",
            "|    std                | 0.998      |\n",
            "|    value_loss         | 14         |\n",
            "--------------------------------------\n",
            "======a2c Validation from:  2021-04-05 to  2021-07-02\n",
            "a2c Sharpe Ratio:  0.17010016570693268\n",
            "======ddpg Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64, 'device': 'cuda'}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ddpg/ddpg_693_1\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 4         |\n",
            "|    fps             | 121       |\n",
            "|    time_elapsed    | 76        |\n",
            "|    total_timesteps | 9308      |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -516      |\n",
            "|    critic_loss     | 275       |\n",
            "|    learning_rate   | 0.0005    |\n",
            "|    n_updates       | 9207      |\n",
            "|    reward          | 14.820918 |\n",
            "----------------------------------\n",
            "======ddpg Validation from:  2021-04-05 to  2021-07-02\n",
            "ddpg Sharpe Ratio:  0.17508575619660555\n",
            "======td3 Training========\n",
            "{'device': 'cuda'}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/td3/td3_693_1\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 4        |\n",
            "|    fps             | 130      |\n",
            "|    time_elapsed    | 71       |\n",
            "|    total_timesteps | 9308     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 128      |\n",
            "|    critic_loss     | 755      |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 9207     |\n",
            "|    reward          | 70.71181 |\n",
            "---------------------------------\n",
            "======td3 Validation from:  2021-04-05 to  2021-07-02\n",
            "td3 Sharpe Ratio:  0.020708898814118054\n",
            "======sac Training========\n",
            "{'device': 'cuda'}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/sac/sac_693_1\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 4        |\n",
            "|    fps             | 74       |\n",
            "|    time_elapsed    | 124      |\n",
            "|    total_timesteps | 9308     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 1.88e+04 |\n",
            "|    critic_loss     | 6.35e+04 |\n",
            "|    ent_coef        | 15.8     |\n",
            "|    ent_coef_loss   | -264     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 9207     |\n",
            "|    reward          | 0.0      |\n",
            "---------------------------------\n",
            "======sac Validation from:  2021-04-05 to  2021-07-02\n",
            "sac Sharpe Ratio:  0.0\n",
            "======ppo Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128, 'device': 'cuda'}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ppo/ppo_693_1\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    fps             | 344       |\n",
            "|    iterations      | 1         |\n",
            "|    time_elapsed    | 5         |\n",
            "|    total_timesteps | 2048      |\n",
            "| train/             |           |\n",
            "|    reward          | 3.2779632 |\n",
            "----------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 350          |\n",
            "|    iterations           | 2            |\n",
            "|    time_elapsed         | 11           |\n",
            "|    total_timesteps      | 4096         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0050706225 |\n",
            "|    clip_fraction        | 0.0528       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -4.26        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 2.14         |\n",
            "|    n_updates            | 10           |\n",
            "|    policy_gradient_loss | -0.00185     |\n",
            "|    reward               | 0.48987615   |\n",
            "|    std                  | 0.999        |\n",
            "|    value_loss           | 4.31         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 332          |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 18           |\n",
            "|    total_timesteps      | 6144         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034612927 |\n",
            "|    clip_fraction        | 0.0357       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -4.25        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 7.46         |\n",
            "|    n_updates            | 20           |\n",
            "|    policy_gradient_loss | -0.00209     |\n",
            "|    reward               | 0.5914769    |\n",
            "|    std                  | 0.995        |\n",
            "|    value_loss           | 15.7         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 338         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 24          |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004758518 |\n",
            "|    clip_fraction        | 0.0307      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.24       |\n",
            "|    explained_variance   | 0.00367     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 21.2        |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.00342    |\n",
            "|    reward               | 0.11441596  |\n",
            "|    std                  | 0.994       |\n",
            "|    value_loss           | 42          |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 331          |\n",
            "|    iterations           | 5            |\n",
            "|    time_elapsed         | 30           |\n",
            "|    total_timesteps      | 10240        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0056822496 |\n",
            "|    clip_fraction        | 0.0408       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -4.23        |\n",
            "|    explained_variance   | 0.0556       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 5.41         |\n",
            "|    n_updates            | 40           |\n",
            "|    policy_gradient_loss | -0.00205     |\n",
            "|    reward               | 0.3508311    |\n",
            "|    std                  | 0.99         |\n",
            "|    value_loss           | 9.07         |\n",
            "------------------------------------------\n",
            "======ppo Validation from:  2021-04-05 to  2021-07-02\n",
            "ppo Sharpe Ratio:  0.18565586543505946\n",
            "======Best Model Retraining from:  2012-01-01 to  2021-07-02\n",
            "======Trading from:  2021-07-02 to  2021-10-01\n",
            "============================================\n",
            "turbulence_threshold:  24.528961738292235\n",
            "======Model training from:  2012-01-01 to  2021-07-02\n",
            "======a2c Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007, 'device': 'cuda'}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/a2c/a2c_756_1\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 294        |\n",
            "|    iterations         | 100        |\n",
            "|    time_elapsed       | 1          |\n",
            "|    total_timesteps    | 500        |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.3       |\n",
            "|    explained_variance | -0.0206    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 99         |\n",
            "|    policy_loss        | -14.3      |\n",
            "|    reward             | -1.9879198 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 10.7       |\n",
            "--------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 293           |\n",
            "|    iterations         | 200           |\n",
            "|    time_elapsed       | 3             |\n",
            "|    total_timesteps    | 1000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.3          |\n",
            "|    explained_variance | -7.15e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 199           |\n",
            "|    policy_loss        | -8.36         |\n",
            "|    reward             | -0.0058665685 |\n",
            "|    std                | 1.02          |\n",
            "|    value_loss         | 11.2          |\n",
            "-----------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 291       |\n",
            "|    iterations         | 300       |\n",
            "|    time_elapsed       | 5         |\n",
            "|    total_timesteps    | 1500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.28     |\n",
            "|    explained_variance | 0.00636   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 299       |\n",
            "|    policy_loss        | 11.4      |\n",
            "|    reward             | 2.9032202 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 20.3      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 292       |\n",
            "|    iterations         | 400       |\n",
            "|    time_elapsed       | 6         |\n",
            "|    total_timesteps    | 2000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.28     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 399       |\n",
            "|    policy_loss        | 17.1      |\n",
            "|    reward             | 6.0418763 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 25        |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 287       |\n",
            "|    iterations         | 500       |\n",
            "|    time_elapsed       | 8         |\n",
            "|    total_timesteps    | 2500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.28     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 499       |\n",
            "|    policy_loss        | -2.86     |\n",
            "|    reward             | 0.8135019 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 0.502     |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 267         |\n",
            "|    iterations         | 600         |\n",
            "|    time_elapsed       | 11          |\n",
            "|    total_timesteps    | 3000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.29       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 599         |\n",
            "|    policy_loss        | 4.97        |\n",
            "|    reward             | -0.67146116 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 4.33        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 270        |\n",
            "|    iterations         | 700        |\n",
            "|    time_elapsed       | 12         |\n",
            "|    total_timesteps    | 3500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.31      |\n",
            "|    explained_variance | 5.96e-08   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 699        |\n",
            "|    policy_loss        | 15.1       |\n",
            "|    reward             | -1.8584417 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 20         |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 273         |\n",
            "|    iterations         | 800         |\n",
            "|    time_elapsed       | 14          |\n",
            "|    total_timesteps    | 4000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.32       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 799         |\n",
            "|    policy_loss        | -7.98       |\n",
            "|    reward             | -0.30035773 |\n",
            "|    std                | 1.02        |\n",
            "|    value_loss         | 18.7        |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 275         |\n",
            "|    iterations         | 900         |\n",
            "|    time_elapsed       | 16          |\n",
            "|    total_timesteps    | 4500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.33       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 899         |\n",
            "|    policy_loss        | -58.1       |\n",
            "|    reward             | -0.28372085 |\n",
            "|    std                | 1.02        |\n",
            "|    value_loss         | 319         |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 276       |\n",
            "|    iterations         | 1000      |\n",
            "|    time_elapsed       | 18        |\n",
            "|    total_timesteps    | 5000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.34     |\n",
            "|    explained_variance | 0.186     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 999       |\n",
            "|    policy_loss        | -21.1     |\n",
            "|    reward             | -1.214392 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 14        |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 278       |\n",
            "|    iterations         | 1100      |\n",
            "|    time_elapsed       | 19        |\n",
            "|    total_timesteps    | 5500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.34     |\n",
            "|    explained_variance | 0.018     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1099      |\n",
            "|    policy_loss        | 4.53      |\n",
            "|    reward             | 2.7693706 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 2.16      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 278       |\n",
            "|    iterations         | 1200      |\n",
            "|    time_elapsed       | 21        |\n",
            "|    total_timesteps    | 6000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.35     |\n",
            "|    explained_variance | -0.0201   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1199      |\n",
            "|    policy_loss        | -13.9     |\n",
            "|    reward             | 2.9700782 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 11.4      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 270       |\n",
            "|    iterations         | 1300      |\n",
            "|    time_elapsed       | 24        |\n",
            "|    total_timesteps    | 6500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.33     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1299      |\n",
            "|    policy_loss        | 42.9      |\n",
            "|    reward             | 3.9407952 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 197       |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 271        |\n",
            "|    iterations         | 1400       |\n",
            "|    time_elapsed       | 25         |\n",
            "|    total_timesteps    | 7000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.33      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1399       |\n",
            "|    policy_loss        | -205       |\n",
            "|    reward             | -13.284203 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 2.68e+03   |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 271        |\n",
            "|    iterations         | 1500       |\n",
            "|    time_elapsed       | 27         |\n",
            "|    total_timesteps    | 7500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.34      |\n",
            "|    explained_variance | 0.302      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1499       |\n",
            "|    policy_loss        | -3.27      |\n",
            "|    reward             | 0.87151855 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 1.54       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 273       |\n",
            "|    iterations         | 1600      |\n",
            "|    time_elapsed       | 29        |\n",
            "|    total_timesteps    | 8000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.33     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1599      |\n",
            "|    policy_loss        | -4.54     |\n",
            "|    reward             | 3.2567837 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 2.97      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 274        |\n",
            "|    iterations         | 1700       |\n",
            "|    time_elapsed       | 31         |\n",
            "|    total_timesteps    | 8500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.35      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1699       |\n",
            "|    policy_loss        | 12.4       |\n",
            "|    reward             | -1.0394574 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 14.9       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 275        |\n",
            "|    iterations         | 1800       |\n",
            "|    time_elapsed       | 32         |\n",
            "|    total_timesteps    | 9000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.34      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1799       |\n",
            "|    policy_loss        | 3.54       |\n",
            "|    reward             | -1.1473254 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 7.42       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 276      |\n",
            "|    iterations         | 1900     |\n",
            "|    time_elapsed       | 34       |\n",
            "|    total_timesteps    | 9500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.33    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1899     |\n",
            "|    policy_loss        | 158      |\n",
            "|    reward             | -2.51475 |\n",
            "|    std                | 1.03     |\n",
            "|    value_loss         | 2.91e+03 |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 271        |\n",
            "|    iterations         | 2000       |\n",
            "|    time_elapsed       | 36         |\n",
            "|    total_timesteps    | 10000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.33      |\n",
            "|    explained_variance | -0.109     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1999       |\n",
            "|    policy_loss        | 12.7       |\n",
            "|    reward             | -3.0597858 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 13.7       |\n",
            "--------------------------------------\n",
            "======a2c Validation from:  2021-07-02 to  2021-10-01\n",
            "a2c Sharpe Ratio:  0.2677240925254289\n",
            "======ddpg Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64, 'device': 'cuda'}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ddpg/ddpg_756_1\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 4         |\n",
            "|    fps             | 119       |\n",
            "|    time_elapsed    | 79        |\n",
            "|    total_timesteps | 9560      |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -2.5e+03  |\n",
            "|    critic_loss     | 193       |\n",
            "|    learning_rate   | 0.0005    |\n",
            "|    n_updates       | 9459      |\n",
            "|    reward          | 2.2904804 |\n",
            "----------------------------------\n",
            "======ddpg Validation from:  2021-07-02 to  2021-10-01\n",
            "ddpg Sharpe Ratio:  -0.10983748480515784\n",
            "======td3 Training========\n",
            "{'device': 'cuda'}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/td3/td3_756_1\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 4         |\n",
            "|    fps             | 127       |\n",
            "|    time_elapsed    | 74        |\n",
            "|    total_timesteps | 9560      |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 2.9e+03   |\n",
            "|    critic_loss     | 1.33e+04  |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 9459      |\n",
            "|    reward          | 2.2904804 |\n",
            "----------------------------------\n",
            "======td3 Validation from:  2021-07-02 to  2021-10-01\n",
            "td3 Sharpe Ratio:  -0.10983748480515784\n",
            "======sac Training========\n",
            "{'device': 'cuda'}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/sac/sac_756_1\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 4        |\n",
            "|    fps             | 73       |\n",
            "|    time_elapsed    | 130      |\n",
            "|    total_timesteps | 9560     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 9.09e+03 |\n",
            "|    critic_loss     | 1.78e+03 |\n",
            "|    ent_coef        | 17.1     |\n",
            "|    ent_coef_loss   | -79.9    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 9459     |\n",
            "|    reward          | 8.050505 |\n",
            "---------------------------------\n",
            "======sac Validation from:  2021-07-02 to  2021-10-01\n",
            "sac Sharpe Ratio:  0.2605240351302736\n",
            "======ppo Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128, 'device': 'cuda'}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ppo/ppo_756_1\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    fps             | 384      |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 5        |\n",
            "|    total_timesteps | 2048     |\n",
            "| train/             |          |\n",
            "|    reward          | 3.366615 |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 360         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 11          |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006349872 |\n",
            "|    clip_fraction        | 0.0525      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.26       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 2.77        |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.00306    |\n",
            "|    reward               | 4.4662137   |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 3.32        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 342         |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 17          |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006208663 |\n",
            "|    clip_fraction        | 0.0313      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.26       |\n",
            "|    explained_variance   | -0.000562   |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 14.2        |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.00282    |\n",
            "|    reward               | 0.2146364   |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 59.1        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 345          |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 23           |\n",
            "|    total_timesteps      | 8192         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026215664 |\n",
            "|    clip_fraction        | 0.00879      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -4.26        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 51.6         |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | -0.00102     |\n",
            "|    reward               | -0.16295116  |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 90.2         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 335          |\n",
            "|    iterations           | 5            |\n",
            "|    time_elapsed         | 30           |\n",
            "|    total_timesteps      | 10240        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039334474 |\n",
            "|    clip_fraction        | 0.0379       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -4.26        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.663        |\n",
            "|    n_updates            | 40           |\n",
            "|    policy_gradient_loss | -0.00158     |\n",
            "|    reward               | 0.0031231618 |\n",
            "|    std                  | 0.999        |\n",
            "|    value_loss           | 1.93         |\n",
            "------------------------------------------\n",
            "======ppo Validation from:  2021-07-02 to  2021-10-01\n",
            "ppo Sharpe Ratio:  0.14584872955821895\n",
            "======Best Model Retraining from:  2012-01-01 to  2021-10-01\n",
            "======Trading from:  2021-10-01 to  2021-12-31\n",
            "============================================\n",
            "turbulence_threshold:  24.528961738292235\n",
            "======Model training from:  2012-01-01 to  2021-10-01\n",
            "======a2c Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007, 'device': 'cuda'}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/a2c/a2c_819_1\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 289        |\n",
            "|    iterations         | 100        |\n",
            "|    time_elapsed       | 1          |\n",
            "|    total_timesteps    | 500        |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.25      |\n",
            "|    explained_variance | -0.00203   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 99         |\n",
            "|    policy_loss        | -6.95      |\n",
            "|    reward             | -1.1889488 |\n",
            "|    std                | 0.999      |\n",
            "|    value_loss         | 4.79       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 292       |\n",
            "|    iterations         | 200       |\n",
            "|    time_elapsed       | 3         |\n",
            "|    total_timesteps    | 1000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.25     |\n",
            "|    explained_variance | 0.0487    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 199       |\n",
            "|    policy_loss        | -5.14     |\n",
            "|    reward             | 1.2006445 |\n",
            "|    std                | 0.999     |\n",
            "|    value_loss         | 4.63      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 292       |\n",
            "|    iterations         | 300       |\n",
            "|    time_elapsed       | 5         |\n",
            "|    total_timesteps    | 1500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.23     |\n",
            "|    explained_variance | -0.00959  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 299       |\n",
            "|    policy_loss        | 7.32      |\n",
            "|    reward             | 3.8651862 |\n",
            "|    std                | 0.989     |\n",
            "|    value_loss         | 13.6      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 270       |\n",
            "|    iterations         | 400       |\n",
            "|    time_elapsed       | 7         |\n",
            "|    total_timesteps    | 2000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.22     |\n",
            "|    explained_variance | 0.0182    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 399       |\n",
            "|    policy_loss        | 13.5      |\n",
            "|    reward             | 4.9363008 |\n",
            "|    std                | 0.986     |\n",
            "|    value_loss         | 42.7      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 260         |\n",
            "|    iterations         | 500         |\n",
            "|    time_elapsed       | 9           |\n",
            "|    total_timesteps    | 2500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.21       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 499         |\n",
            "|    policy_loss        | 0.0559      |\n",
            "|    reward             | 0.030566607 |\n",
            "|    std                | 0.986       |\n",
            "|    value_loss         | 0.00516     |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 265        |\n",
            "|    iterations         | 600        |\n",
            "|    time_elapsed       | 11         |\n",
            "|    total_timesteps    | 3000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.22      |\n",
            "|    explained_variance | -0.0917    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 599        |\n",
            "|    policy_loss        | -1.37      |\n",
            "|    reward             | -0.5331632 |\n",
            "|    std                | 0.988      |\n",
            "|    value_loss         | 0.55       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 268       |\n",
            "|    iterations         | 700       |\n",
            "|    time_elapsed       | 13        |\n",
            "|    total_timesteps    | 3500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.21     |\n",
            "|    explained_variance | -0.0752   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 699       |\n",
            "|    policy_loss        | -1.85     |\n",
            "|    reward             | 1.1507115 |\n",
            "|    std                | 0.984     |\n",
            "|    value_loss         | 4.67      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 271       |\n",
            "|    iterations         | 800       |\n",
            "|    time_elapsed       | 14        |\n",
            "|    total_timesteps    | 4000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.23     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 799       |\n",
            "|    policy_loss        | 15.2      |\n",
            "|    reward             | 3.7869167 |\n",
            "|    std                | 0.99      |\n",
            "|    value_loss         | 52.9      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 274        |\n",
            "|    iterations         | 900        |\n",
            "|    time_elapsed       | 16         |\n",
            "|    total_timesteps    | 4500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.24      |\n",
            "|    explained_variance | -0.064     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 899        |\n",
            "|    policy_loss        | -5.74      |\n",
            "|    reward             | -43.601986 |\n",
            "|    std                | 0.995      |\n",
            "|    value_loss         | 58.5       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 275         |\n",
            "|    iterations         | 1000        |\n",
            "|    time_elapsed       | 18          |\n",
            "|    total_timesteps    | 5000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.26       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 999         |\n",
            "|    policy_loss        | -0.188      |\n",
            "|    reward             | -0.27370295 |\n",
            "|    std                | 1           |\n",
            "|    value_loss         | 0.131       |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 271         |\n",
            "|    iterations         | 1100        |\n",
            "|    time_elapsed       | 20          |\n",
            "|    total_timesteps    | 5500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.27       |\n",
            "|    explained_variance | -0.00428    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1099        |\n",
            "|    policy_loss        | -11.2       |\n",
            "|    reward             | 0.074237004 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 4.67        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 266        |\n",
            "|    iterations         | 1200       |\n",
            "|    time_elapsed       | 22         |\n",
            "|    total_timesteps    | 6000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.27      |\n",
            "|    explained_variance | -0.0133    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1199       |\n",
            "|    policy_loss        | -15.8      |\n",
            "|    reward             | -0.9301934 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 24.2       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 267       |\n",
            "|    iterations         | 1300      |\n",
            "|    time_elapsed       | 24        |\n",
            "|    total_timesteps    | 6500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.26     |\n",
            "|    explained_variance | -0.0792   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1299      |\n",
            "|    policy_loss        | 17.8      |\n",
            "|    reward             | 1.9290947 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 26.7      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 269       |\n",
            "|    iterations         | 1400      |\n",
            "|    time_elapsed       | 25        |\n",
            "|    total_timesteps    | 7000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.26     |\n",
            "|    explained_variance | -0.027    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1399      |\n",
            "|    policy_loss        | -11.7     |\n",
            "|    reward             | 23.779924 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 99.5      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 271        |\n",
            "|    iterations         | 1500       |\n",
            "|    time_elapsed       | 27         |\n",
            "|    total_timesteps    | 7500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.27      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1499       |\n",
            "|    policy_loss        | 0.399      |\n",
            "|    reward             | -1.3815013 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 0.103      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 272        |\n",
            "|    iterations         | 1600       |\n",
            "|    time_elapsed       | 29         |\n",
            "|    total_timesteps    | 8000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.29      |\n",
            "|    explained_variance | 0.00125    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1599       |\n",
            "|    policy_loss        | 5.12       |\n",
            "|    reward             | 0.85588783 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 2.82       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 273        |\n",
            "|    iterations         | 1700       |\n",
            "|    time_elapsed       | 31         |\n",
            "|    total_timesteps    | 8500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.3       |\n",
            "|    explained_variance | -0.0692    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1699       |\n",
            "|    policy_loss        | 13.4       |\n",
            "|    reward             | -0.8956587 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 15.6       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 271      |\n",
            "|    iterations         | 1800     |\n",
            "|    time_elapsed       | 33       |\n",
            "|    total_timesteps    | 9000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.29    |\n",
            "|    explained_variance | -0.0131  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1799     |\n",
            "|    policy_loss        | -12.3    |\n",
            "|    reward             | 4.528942 |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 15.5     |\n",
            "------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 267         |\n",
            "|    iterations         | 1900        |\n",
            "|    time_elapsed       | 35          |\n",
            "|    total_timesteps    | 9500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.29       |\n",
            "|    explained_variance | -0.00537    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1899        |\n",
            "|    policy_loss        | -7.61       |\n",
            "|    reward             | -0.85425323 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 67.3        |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 268         |\n",
            "|    iterations         | 2000        |\n",
            "|    time_elapsed       | 37          |\n",
            "|    total_timesteps    | 10000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.31       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1999        |\n",
            "|    policy_loss        | -4.09       |\n",
            "|    reward             | -0.50202525 |\n",
            "|    std                | 1.02        |\n",
            "|    value_loss         | 1.18        |\n",
            "---------------------------------------\n",
            "======a2c Validation from:  2021-10-01 to  2021-12-31\n",
            "a2c Sharpe Ratio:  0.3756647371401744\n",
            "======ddpg Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64, 'device': 'cuda'}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ddpg/ddpg_819_1\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 4         |\n",
            "|    fps             | 120       |\n",
            "|    time_elapsed    | 81        |\n",
            "|    total_timesteps | 9812      |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -8.71e+03 |\n",
            "|    critic_loss     | 76.4      |\n",
            "|    learning_rate   | 0.0005    |\n",
            "|    n_updates       | 9711      |\n",
            "|    reward          | 0.0       |\n",
            "----------------------------------\n",
            "======ddpg Validation from:  2021-10-01 to  2021-12-31\n",
            "ddpg Sharpe Ratio:  0.0\n",
            "======td3 Training========\n",
            "{'device': 'cuda'}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/td3/td3_819_1\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 4        |\n",
            "|    fps             | 127      |\n",
            "|    time_elapsed    | 76       |\n",
            "|    total_timesteps | 9812     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 1.76e+04 |\n",
            "|    critic_loss     | 1.41e+04 |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 9711     |\n",
            "|    reward          | 0.0      |\n",
            "---------------------------------\n",
            "======td3 Validation from:  2021-10-01 to  2021-12-31\n",
            "td3 Sharpe Ratio:  0.0\n",
            "======sac Training========\n",
            "{'device': 'cuda'}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/sac/sac_819_1\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 4        |\n",
            "|    fps             | 73       |\n",
            "|    time_elapsed    | 133      |\n",
            "|    total_timesteps | 9812     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 2.18e+04 |\n",
            "|    critic_loss     | 2.06e+04 |\n",
            "|    ent_coef        | 18.4     |\n",
            "|    ent_coef_loss   | -148     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 9711     |\n",
            "|    reward          | 4.051927 |\n",
            "---------------------------------\n",
            "======sac Validation from:  2021-10-01 to  2021-12-31\n",
            "sac Sharpe Ratio:  0.12392215163579824\n",
            "======ppo Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128, 'device': 'cuda'}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ppo/ppo_819_1\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    fps             | 404       |\n",
            "|    iterations      | 1         |\n",
            "|    time_elapsed    | 5         |\n",
            "|    total_timesteps | 2048      |\n",
            "| train/             |           |\n",
            "|    reward          | 0.5051278 |\n",
            "----------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 343          |\n",
            "|    iterations           | 2            |\n",
            "|    time_elapsed         | 11           |\n",
            "|    total_timesteps      | 4096         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0074686715 |\n",
            "|    clip_fraction        | 0.0641       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -4.25        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.454        |\n",
            "|    n_updates            | 10           |\n",
            "|    policy_gradient_loss | -0.00286     |\n",
            "|    reward               | 0.24325529   |\n",
            "|    std                  | 0.998        |\n",
            "|    value_loss           | 1.06         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 347          |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 17           |\n",
            "|    total_timesteps      | 6144         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0059363577 |\n",
            "|    clip_fraction        | 0.0458       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -4.25        |\n",
            "|    explained_variance   | 0.00227      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 8.45         |\n",
            "|    n_updates            | 20           |\n",
            "|    policy_gradient_loss | -0.0034      |\n",
            "|    reward               | -0.4453872   |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 18.1         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 334          |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 24           |\n",
            "|    total_timesteps      | 8192         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024297053 |\n",
            "|    clip_fraction        | 0.0062       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -4.26        |\n",
            "|    explained_variance   | -0.0135      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 24.4         |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | -0.0019      |\n",
            "|    reward               | 0.34027147   |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 49.3         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 338          |\n",
            "|    iterations           | 5            |\n",
            "|    time_elapsed         | 30           |\n",
            "|    total_timesteps      | 10240        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031324932 |\n",
            "|    clip_fraction        | 0.0064       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -4.27        |\n",
            "|    explained_variance   | 0.0259       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 42.8         |\n",
            "|    n_updates            | 40           |\n",
            "|    policy_gradient_loss | -0.00219     |\n",
            "|    reward               | -0.1551878   |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 51.5         |\n",
            "------------------------------------------\n",
            "======ppo Validation from:  2021-10-01 to  2021-12-31\n",
            "ppo Sharpe Ratio:  0.15304252092176704\n",
            "======Best Model Retraining from:  2012-01-01 to  2021-12-31\n",
            "======Trading from:  2021-12-31 to  2022-04-01\n",
            "============================================\n",
            "turbulence_threshold:  24.528961738292235\n",
            "======Model training from:  2012-01-01 to  2021-12-31\n",
            "======a2c Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007, 'device': 'cuda'}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/a2c/a2c_882_1\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 285        |\n",
            "|    iterations         | 100        |\n",
            "|    time_elapsed       | 1          |\n",
            "|    total_timesteps    | 500        |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.26      |\n",
            "|    explained_variance | -0.182     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 99         |\n",
            "|    policy_loss        | -8.57      |\n",
            "|    reward             | -1.2380437 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 6.15       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 263       |\n",
            "|    iterations         | 200       |\n",
            "|    time_elapsed       | 3         |\n",
            "|    total_timesteps    | 1000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.26     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 199       |\n",
            "|    policy_loss        | -6.04     |\n",
            "|    reward             | 1.3245481 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 4.72      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 246      |\n",
            "|    iterations         | 300      |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 1500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.26    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 299      |\n",
            "|    policy_loss        | 8.34     |\n",
            "|    reward             | 4.011179 |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 13.6     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 256       |\n",
            "|    iterations         | 400       |\n",
            "|    time_elapsed       | 7         |\n",
            "|    total_timesteps    | 2000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.25     |\n",
            "|    explained_variance | -0.00231  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 399       |\n",
            "|    policy_loss        | 16.5      |\n",
            "|    reward             | 5.1740127 |\n",
            "|    std                | 0.996     |\n",
            "|    value_loss         | 46.8      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 262       |\n",
            "|    iterations         | 500       |\n",
            "|    time_elapsed       | 9         |\n",
            "|    total_timesteps    | 2500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.25     |\n",
            "|    explained_variance | 0.0907    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 499       |\n",
            "|    policy_loss        | 156       |\n",
            "|    reward             | 16.336226 |\n",
            "|    std                | 0.997     |\n",
            "|    value_loss         | 770       |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 266       |\n",
            "|    iterations         | 600       |\n",
            "|    time_elapsed       | 11        |\n",
            "|    total_timesteps    | 3000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.26     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 599       |\n",
            "|    policy_loss        | 4.41      |\n",
            "|    reward             | 1.7875233 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 2.03      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 268       |\n",
            "|    iterations         | 700       |\n",
            "|    time_elapsed       | 13        |\n",
            "|    total_timesteps    | 3500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.25     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 699       |\n",
            "|    policy_loss        | 11.9      |\n",
            "|    reward             | 0.1895178 |\n",
            "|    std                | 0.998     |\n",
            "|    value_loss         | 14.4      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 271        |\n",
            "|    iterations         | 800        |\n",
            "|    time_elapsed       | 14         |\n",
            "|    total_timesteps    | 4000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.23      |\n",
            "|    explained_variance | 0.0197     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 799        |\n",
            "|    policy_loss        | -13.5      |\n",
            "|    reward             | -0.6249459 |\n",
            "|    std                | 0.99       |\n",
            "|    value_loss         | 9.06       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 268        |\n",
            "|    iterations         | 900        |\n",
            "|    time_elapsed       | 16         |\n",
            "|    total_timesteps    | 4500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.21      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 899        |\n",
            "|    policy_loss        | 15         |\n",
            "|    reward             | -2.3464975 |\n",
            "|    std                | 0.983      |\n",
            "|    value_loss         | 27.2       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 262       |\n",
            "|    iterations         | 1000      |\n",
            "|    time_elapsed       | 19        |\n",
            "|    total_timesteps    | 5000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.2      |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 999       |\n",
            "|    policy_loss        | 40.4      |\n",
            "|    reward             | 11.145255 |\n",
            "|    std                | 0.981     |\n",
            "|    value_loss         | 153       |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 264        |\n",
            "|    iterations         | 1100       |\n",
            "|    time_elapsed       | 20         |\n",
            "|    total_timesteps    | 5500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.18      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1099       |\n",
            "|    policy_loss        | 5.37       |\n",
            "|    reward             | -0.5703079 |\n",
            "|    std                | 0.976      |\n",
            "|    value_loss         | 2.29       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 266        |\n",
            "|    iterations         | 1200       |\n",
            "|    time_elapsed       | 22         |\n",
            "|    total_timesteps    | 6000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.19      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1199       |\n",
            "|    policy_loss        | 1.56       |\n",
            "|    reward             | -1.2256904 |\n",
            "|    std                | 0.979      |\n",
            "|    value_loss         | 2.87       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 268        |\n",
            "|    iterations         | 1300       |\n",
            "|    time_elapsed       | 24         |\n",
            "|    total_timesteps    | 6500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.22      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1299       |\n",
            "|    policy_loss        | -0.0741    |\n",
            "|    reward             | -1.2811202 |\n",
            "|    std                | 0.988      |\n",
            "|    value_loss         | 1.84       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 270         |\n",
            "|    iterations         | 1400        |\n",
            "|    time_elapsed       | 25          |\n",
            "|    total_timesteps    | 7000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.24       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1399        |\n",
            "|    policy_loss        | -15.5       |\n",
            "|    reward             | -0.98957855 |\n",
            "|    std                | 0.993       |\n",
            "|    value_loss         | 16          |\n",
            "---------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 271      |\n",
            "|    iterations         | 1500     |\n",
            "|    time_elapsed       | 27       |\n",
            "|    total_timesteps    | 7500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.23    |\n",
            "|    explained_variance | 1.79e-07 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1499     |\n",
            "|    policy_loss        | 101      |\n",
            "|    reward             | 15.14439 |\n",
            "|    std                | 0.991    |\n",
            "|    value_loss         | 572      |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 269       |\n",
            "|    iterations         | 1600      |\n",
            "|    time_elapsed       | 29        |\n",
            "|    total_timesteps    | 8000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.23     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1599      |\n",
            "|    policy_loss        | 2.16      |\n",
            "|    reward             | 0.4983045 |\n",
            "|    std                | 0.99      |\n",
            "|    value_loss         | 1.31      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 265        |\n",
            "|    iterations         | 1700       |\n",
            "|    time_elapsed       | 31         |\n",
            "|    total_timesteps    | 8500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.23      |\n",
            "|    explained_variance | -0.0128    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1699       |\n",
            "|    policy_loss        | 3.67       |\n",
            "|    reward             | 0.50371146 |\n",
            "|    std                | 0.989      |\n",
            "|    value_loss         | 9.84       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 267       |\n",
            "|    iterations         | 1800      |\n",
            "|    time_elapsed       | 33        |\n",
            "|    total_timesteps    | 9000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.2      |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1799      |\n",
            "|    policy_loss        | 11.1      |\n",
            "|    reward             | 1.1492908 |\n",
            "|    std                | 0.981     |\n",
            "|    value_loss         | 5.79      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 268       |\n",
            "|    iterations         | 1900      |\n",
            "|    time_elapsed       | 35        |\n",
            "|    total_timesteps    | 9500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.2      |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1899      |\n",
            "|    policy_loss        | -16.5     |\n",
            "|    reward             | 1.3477751 |\n",
            "|    std                | 0.982     |\n",
            "|    value_loss         | 26        |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 269       |\n",
            "|    iterations         | 2000      |\n",
            "|    time_elapsed       | 37        |\n",
            "|    total_timesteps    | 10000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.19     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1999      |\n",
            "|    policy_loss        | -24.6     |\n",
            "|    reward             | 3.3162472 |\n",
            "|    std                | 0.975     |\n",
            "|    value_loss         | 205       |\n",
            "-------------------------------------\n",
            "======a2c Validation from:  2021-12-31 to  2022-04-01\n",
            "a2c Sharpe Ratio:  -0.02620874372091701\n",
            "======ddpg Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64, 'device': 'cuda'}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ddpg/ddpg_882_1\n",
            "day: 2515, episode: 5\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 10987827.41\n",
            "total_reward: 9987827.41\n",
            "total_cost: 1183.55\n",
            "total_trades: 7343\n",
            "Sharpe: 1.193\n",
            "=================================\n",
            "======ddpg Validation from:  2021-12-31 to  2022-04-01\n",
            "ddpg Sharpe Ratio:  -0.08653444507668344\n",
            "======td3 Training========\n",
            "{'device': 'cuda'}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/td3/td3_882_1\n",
            "day: 2515, episode: 10\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 22037905.96\n",
            "total_reward: 21037905.96\n",
            "total_cost: 999.00\n",
            "total_trades: 7229\n",
            "Sharpe: 1.288\n",
            "=================================\n",
            "======td3 Validation from:  2021-12-31 to  2022-04-01\n",
            "td3 Sharpe Ratio:  -0.09955061089206726\n",
            "======sac Training========\n",
            "{'device': 'cuda'}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/sac/sac_882_1\n",
            "day: 2515, episode: 15\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 35834748.62\n",
            "total_reward: 34834748.62\n",
            "total_cost: 999.00\n",
            "total_trades: 2515\n",
            "Sharpe: 0.970\n",
            "=================================\n",
            "======sac Validation from:  2021-12-31 to  2022-04-01\n",
            "sac Sharpe Ratio:  -0.12515022943996468\n",
            "======ppo Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128, 'device': 'cuda'}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ppo/ppo_882_1\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    fps             | 341       |\n",
            "|    iterations      | 1         |\n",
            "|    time_elapsed    | 5         |\n",
            "|    total_timesteps | 2048      |\n",
            "| train/             |           |\n",
            "|    reward          | 1.4968995 |\n",
            "----------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 343          |\n",
            "|    iterations           | 2            |\n",
            "|    time_elapsed         | 11           |\n",
            "|    total_timesteps      | 4096         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.006241304  |\n",
            "|    clip_fraction        | 0.0611       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -4.25        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.42         |\n",
            "|    n_updates            | 10           |\n",
            "|    policy_gradient_loss | -0.0036      |\n",
            "|    reward               | -0.014430005 |\n",
            "|    std                  | 0.995        |\n",
            "|    value_loss           | 3.37         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 335          |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 18           |\n",
            "|    total_timesteps      | 6144         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.005289592  |\n",
            "|    clip_fraction        | 0.0318       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -4.24        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 16.3         |\n",
            "|    n_updates            | 20           |\n",
            "|    policy_gradient_loss | -0.0015      |\n",
            "|    reward               | -0.016244847 |\n",
            "|    std                  | 0.995        |\n",
            "|    value_loss           | 26.2         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 333          |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 24           |\n",
            "|    total_timesteps      | 8192         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0045931228 |\n",
            "|    clip_fraction        | 0.0396       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -4.24        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.583        |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | -0.00215     |\n",
            "|    reward               | 0.011429343  |\n",
            "|    std                  | 0.992        |\n",
            "|    value_loss           | 0.976        |\n",
            "------------------------------------------\n",
            "day: 2515, episode: 20\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1279874.93\n",
            "total_reward: 279874.93\n",
            "total_cost: 27730.21\n",
            "total_trades: 7008\n",
            "Sharpe: 0.861\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 332         |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 30          |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004385989 |\n",
            "|    clip_fraction        | 0.0155      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.23       |\n",
            "|    explained_variance   | -0.00154    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 5.58        |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.00114    |\n",
            "|    reward               | 0.008086836 |\n",
            "|    std                  | 0.99        |\n",
            "|    value_loss           | 12          |\n",
            "-----------------------------------------\n",
            "======ppo Validation from:  2021-12-31 to  2022-04-01\n",
            "ppo Sharpe Ratio:  -0.07406025058519486\n",
            "======Best Model Retraining from:  2012-01-01 to  2022-04-01\n",
            "======Trading from:  2022-04-01 to  2022-07-05\n",
            "============================================\n",
            "turbulence_threshold:  24.528961738292235\n",
            "======Model training from:  2012-01-01 to  2022-04-01\n",
            "======a2c Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007, 'device': 'cuda'}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/a2c/a2c_945_1\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 260        |\n",
            "|    iterations         | 100        |\n",
            "|    time_elapsed       | 1          |\n",
            "|    total_timesteps    | 500        |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.28      |\n",
            "|    explained_variance | -0.0181    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 99         |\n",
            "|    policy_loss        | -7.52      |\n",
            "|    reward             | -1.1663879 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 4.39       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 272       |\n",
            "|    iterations         | 200       |\n",
            "|    time_elapsed       | 3         |\n",
            "|    total_timesteps    | 1000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.28     |\n",
            "|    explained_variance | 0.0657    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 199       |\n",
            "|    policy_loss        | -5.14     |\n",
            "|    reward             | 1.2639997 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 4.66      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 278       |\n",
            "|    iterations         | 300       |\n",
            "|    time_elapsed       | 5         |\n",
            "|    total_timesteps    | 1500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.26     |\n",
            "|    explained_variance | -0.000152 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 299       |\n",
            "|    policy_loss        | 7.41      |\n",
            "|    reward             | 3.9188464 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 13.5      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 280       |\n",
            "|    iterations         | 400       |\n",
            "|    time_elapsed       | 7         |\n",
            "|    total_timesteps    | 2000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.27     |\n",
            "|    explained_variance | -0.0184   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 399       |\n",
            "|    policy_loss        | 18.1      |\n",
            "|    reward             | 4.8308725 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 40.9      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 280       |\n",
            "|    iterations         | 500       |\n",
            "|    time_elapsed       | 8         |\n",
            "|    total_timesteps    | 2500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.28     |\n",
            "|    explained_variance | 1.79e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 499       |\n",
            "|    policy_loss        | 92.5      |\n",
            "|    reward             | 14.641043 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 378       |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 280       |\n",
            "|    iterations         | 600       |\n",
            "|    time_elapsed       | 10        |\n",
            "|    total_timesteps    | 3000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.27     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 599       |\n",
            "|    policy_loss        | -8.51     |\n",
            "|    reward             | 0.3615586 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 11.4      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 266       |\n",
            "|    iterations         | 700       |\n",
            "|    time_elapsed       | 13        |\n",
            "|    total_timesteps    | 3500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.29     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 699       |\n",
            "|    policy_loss        | -21.6     |\n",
            "|    reward             | -3.811093 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 107       |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 266         |\n",
            "|    iterations         | 800         |\n",
            "|    time_elapsed       | 15          |\n",
            "|    total_timesteps    | 4000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.31       |\n",
            "|    explained_variance | 0.0113      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 799         |\n",
            "|    policy_loss        | -11.8       |\n",
            "|    reward             | -0.16654432 |\n",
            "|    std                | 1.02        |\n",
            "|    value_loss         | 13.3        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 268        |\n",
            "|    iterations         | 900        |\n",
            "|    time_elapsed       | 16         |\n",
            "|    total_timesteps    | 4500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.31      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 899        |\n",
            "|    policy_loss        | -18.5      |\n",
            "|    reward             | 0.32342213 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 13.4       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 271       |\n",
            "|    iterations         | 1000      |\n",
            "|    time_elapsed       | 18        |\n",
            "|    total_timesteps    | 5000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.33     |\n",
            "|    explained_variance | 0.00561   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 999       |\n",
            "|    policy_loss        | 8.97      |\n",
            "|    reward             | 3.8302503 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 9.14      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 272       |\n",
            "|    iterations         | 1100      |\n",
            "|    time_elapsed       | 20        |\n",
            "|    total_timesteps    | 5500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.34     |\n",
            "|    explained_variance | 0.0342    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1099      |\n",
            "|    policy_loss        | -0.713    |\n",
            "|    reward             | 0.3896702 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 1.29      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 274        |\n",
            "|    iterations         | 1200       |\n",
            "|    time_elapsed       | 21         |\n",
            "|    total_timesteps    | 6000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.33      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1199       |\n",
            "|    policy_loss        | -2.14      |\n",
            "|    reward             | 0.34461582 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 1.26       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 275         |\n",
            "|    iterations         | 1300        |\n",
            "|    time_elapsed       | 23          |\n",
            "|    total_timesteps    | 6500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.34       |\n",
            "|    explained_variance | 0.00909     |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1299        |\n",
            "|    policy_loss        | 9.1         |\n",
            "|    reward             | -0.07783543 |\n",
            "|    std                | 1.03        |\n",
            "|    value_loss         | 12.1        |\n",
            "---------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 268      |\n",
            "|    iterations         | 1400     |\n",
            "|    time_elapsed       | 26       |\n",
            "|    total_timesteps    | 7000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.35    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1399     |\n",
            "|    policy_loss        | 36       |\n",
            "|    reward             | 6.416235 |\n",
            "|    std                | 1.03     |\n",
            "|    value_loss         | 84.8     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 268       |\n",
            "|    iterations         | 1500      |\n",
            "|    time_elapsed       | 27        |\n",
            "|    total_timesteps    | 7500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.35     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1499      |\n",
            "|    policy_loss        | 11.9      |\n",
            "|    reward             | 14.528407 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 30.3      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 270        |\n",
            "|    iterations         | 1600       |\n",
            "|    time_elapsed       | 29         |\n",
            "|    total_timesteps    | 8000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.35      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1599       |\n",
            "|    policy_loss        | -6.21      |\n",
            "|    reward             | 0.58880705 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 1.48       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 271       |\n",
            "|    iterations         | 1700      |\n",
            "|    time_elapsed       | 31        |\n",
            "|    total_timesteps    | 8500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.36     |\n",
            "|    explained_variance | -0.00128  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1699      |\n",
            "|    policy_loss        | -0.0928   |\n",
            "|    reward             | 1.0766382 |\n",
            "|    std                | 1.04      |\n",
            "|    value_loss         | 5.49      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 272       |\n",
            "|    iterations         | 1800      |\n",
            "|    time_elapsed       | 33        |\n",
            "|    total_timesteps    | 9000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.36     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1799      |\n",
            "|    policy_loss        | -5.49     |\n",
            "|    reward             | 0.5716574 |\n",
            "|    std                | 1.04      |\n",
            "|    value_loss         | 2.54      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 273       |\n",
            "|    iterations         | 1900      |\n",
            "|    time_elapsed       | 34        |\n",
            "|    total_timesteps    | 9500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.38     |\n",
            "|    explained_variance | -2.38e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1899      |\n",
            "|    policy_loss        | 27.2      |\n",
            "|    reward             | 5.7186165 |\n",
            "|    std                | 1.04      |\n",
            "|    value_loss         | 92.2      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 273        |\n",
            "|    iterations         | 2000       |\n",
            "|    time_elapsed       | 36         |\n",
            "|    total_timesteps    | 10000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.39      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1999       |\n",
            "|    policy_loss        | 67.2       |\n",
            "|    reward             | -7.3251333 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 408        |\n",
            "--------------------------------------\n",
            "======a2c Validation from:  2022-04-01 to  2022-07-05\n",
            "a2c Sharpe Ratio:  -0.16634487535807727\n",
            "======ddpg Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64, 'device': 'cuda'}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ddpg/ddpg_945_1\n",
            "day: 2578, episode: 5\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 998776.91\n",
            "total_reward: -1223.09\n",
            "total_cost: 233.46\n",
            "total_trades: 291\n",
            "Sharpe: -0.163\n",
            "=================================\n",
            "======ddpg Validation from:  2022-04-01 to  2022-07-05\n",
            "ddpg Sharpe Ratio:  0.0\n",
            "======td3 Training========\n",
            "{'device': 'cuda'}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/td3/td3_945_1\n",
            "day: 2578, episode: 10\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1000000.00\n",
            "total_reward: 0.00\n",
            "total_cost: 0.00\n",
            "total_trades: 0\n",
            "=================================\n",
            "======td3 Validation from:  2022-04-01 to  2022-07-05\n",
            "td3 Sharpe Ratio:  0.0\n",
            "======sac Training========\n",
            "{'device': 'cuda'}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/sac/sac_945_1\n",
            "day: 2578, episode: 15\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 36957062.62\n",
            "total_reward: 35957062.62\n",
            "total_cost: 999.00\n",
            "total_trades: 2578\n",
            "Sharpe: 0.950\n",
            "=================================\n",
            "======sac Validation from:  2022-04-01 to  2022-07-05\n",
            "sac Sharpe Ratio:  -0.21153207260247814\n",
            "======ppo Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128, 'device': 'cuda'}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ppo/ppo_945_1\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    fps             | 338       |\n",
            "|    iterations      | 1         |\n",
            "|    time_elapsed    | 6         |\n",
            "|    total_timesteps | 2048      |\n",
            "| train/             |           |\n",
            "|    reward          | 0.7758552 |\n",
            "----------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 344          |\n",
            "|    iterations           | 2            |\n",
            "|    time_elapsed         | 11           |\n",
            "|    total_timesteps      | 4096         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0060226796 |\n",
            "|    clip_fraction        | 0.0514       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -4.25        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0955       |\n",
            "|    n_updates            | 10           |\n",
            "|    policy_gradient_loss | -0.00311     |\n",
            "|    reward               | 0.4566964    |\n",
            "|    std                  | 0.999        |\n",
            "|    value_loss           | 0.238        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 326         |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 18          |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004334838 |\n",
            "|    clip_fraction        | 0.0308      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.24       |\n",
            "|    explained_variance   | 0.000704    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 2.24        |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.0027     |\n",
            "|    reward               | -0.22180256 |\n",
            "|    std                  | 0.992       |\n",
            "|    value_loss           | 3.97        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 331         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 24          |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003169703 |\n",
            "|    clip_fraction        | 0.00811     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.23       |\n",
            "|    explained_variance   | 0.00935     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 29.3        |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.0025     |\n",
            "|    reward               | -0.03555496 |\n",
            "|    std                  | 0.993       |\n",
            "|    value_loss           | 54.2        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 323         |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 31          |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002961561 |\n",
            "|    clip_fraction        | 0.00518     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.23       |\n",
            "|    explained_variance   | 0.0365      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 35.7        |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.00331    |\n",
            "|    reward               | 7.5870705   |\n",
            "|    std                  | 0.992       |\n",
            "|    value_loss           | 81.8        |\n",
            "-----------------------------------------\n",
            "======ppo Validation from:  2022-04-01 to  2022-07-05\n",
            "ppo Sharpe Ratio:  -0.2774255924956984\n",
            "======Best Model Retraining from:  2012-01-01 to  2022-07-05\n",
            "======Trading from:  2022-07-05 to  2022-10-03\n",
            "Ensemble Strategy took:  85.23401112953822  minutes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 543
        },
        "id": "5pNSgSBXwSzz",
        "outputId": "76750a5c-48f7-4466-eab6-193022f5c28a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Iter   Val Start     Val End Model Used A2C Sharpe PPO Sharpe DDPG Sharpe  \\\n",
              "0   126  2019-01-02  2019-04-03        TD3   0.392953   0.392095    0.288028   \n",
              "1   189  2019-04-03  2019-07-03        TD3   0.244758    0.09207    0.123611   \n",
              "2   252  2019-07-03  2019-10-02       DDPG   0.080109   0.077799     0.23847   \n",
              "3   315  2019-10-02  2020-01-02        A2C   0.701236   0.378293     0.61495   \n",
              "4   378  2020-01-02  2020-04-02        TD3   0.009219   -0.28212         0.0   \n",
              "5   441  2020-04-02  2020-07-02       DDPG     0.4096   0.389613     0.44787   \n",
              "6   504  2020-07-02  2020-10-01        SAC   0.217419   0.073249         0.0   \n",
              "7   567  2020-10-01  2020-12-31       DDPG   0.307694   0.313013    0.478353   \n",
              "8   630  2020-12-31  2021-04-05        A2C   0.095756   0.025216         0.0   \n",
              "9   693  2021-04-05  2021-07-02        PPO     0.1701   0.185656    0.175086   \n",
              "10  756  2021-07-02  2021-10-01        A2C   0.267724   0.145849   -0.109837   \n",
              "11  819  2021-10-01  2021-12-31        A2C   0.375665   0.153043         0.0   \n",
              "12  882  2021-12-31  2022-04-01        A2C  -0.026209   -0.07406   -0.086534   \n",
              "13  945  2022-04-01  2022-07-05       DDPG  -0.166345  -0.277426         0.0   \n",
              "\n",
              "   SAC Sharpe TD3 Sharpe  \n",
              "0    0.288028   0.409691  \n",
              "1    0.076526   0.273206  \n",
              "2    0.137298   0.067508  \n",
              "3     0.61495   0.449607  \n",
              "4   -0.088835   0.073954  \n",
              "5         0.0        0.0  \n",
              "6    0.292272   0.286315  \n",
              "7    0.403345   0.403345  \n",
              "8         0.0  -0.052197  \n",
              "9         0.0   0.020709  \n",
              "10   0.260524  -0.109837  \n",
              "11   0.123922        0.0  \n",
              "12   -0.12515  -0.099551  \n",
              "13  -0.211532        0.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2122e869-5ec1-48a1-b545-4b033f27fa50\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Iter</th>\n",
              "      <th>Val Start</th>\n",
              "      <th>Val End</th>\n",
              "      <th>Model Used</th>\n",
              "      <th>A2C Sharpe</th>\n",
              "      <th>PPO Sharpe</th>\n",
              "      <th>DDPG Sharpe</th>\n",
              "      <th>SAC Sharpe</th>\n",
              "      <th>TD3 Sharpe</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>126</td>\n",
              "      <td>2019-01-02</td>\n",
              "      <td>2019-04-03</td>\n",
              "      <td>TD3</td>\n",
              "      <td>0.392953</td>\n",
              "      <td>0.392095</td>\n",
              "      <td>0.288028</td>\n",
              "      <td>0.288028</td>\n",
              "      <td>0.409691</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>189</td>\n",
              "      <td>2019-04-03</td>\n",
              "      <td>2019-07-03</td>\n",
              "      <td>TD3</td>\n",
              "      <td>0.244758</td>\n",
              "      <td>0.09207</td>\n",
              "      <td>0.123611</td>\n",
              "      <td>0.076526</td>\n",
              "      <td>0.273206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>252</td>\n",
              "      <td>2019-07-03</td>\n",
              "      <td>2019-10-02</td>\n",
              "      <td>DDPG</td>\n",
              "      <td>0.080109</td>\n",
              "      <td>0.077799</td>\n",
              "      <td>0.23847</td>\n",
              "      <td>0.137298</td>\n",
              "      <td>0.067508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>315</td>\n",
              "      <td>2019-10-02</td>\n",
              "      <td>2020-01-02</td>\n",
              "      <td>A2C</td>\n",
              "      <td>0.701236</td>\n",
              "      <td>0.378293</td>\n",
              "      <td>0.61495</td>\n",
              "      <td>0.61495</td>\n",
              "      <td>0.449607</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>378</td>\n",
              "      <td>2020-01-02</td>\n",
              "      <td>2020-04-02</td>\n",
              "      <td>TD3</td>\n",
              "      <td>0.009219</td>\n",
              "      <td>-0.28212</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.088835</td>\n",
              "      <td>0.073954</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>441</td>\n",
              "      <td>2020-04-02</td>\n",
              "      <td>2020-07-02</td>\n",
              "      <td>DDPG</td>\n",
              "      <td>0.4096</td>\n",
              "      <td>0.389613</td>\n",
              "      <td>0.44787</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>504</td>\n",
              "      <td>2020-07-02</td>\n",
              "      <td>2020-10-01</td>\n",
              "      <td>SAC</td>\n",
              "      <td>0.217419</td>\n",
              "      <td>0.073249</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.292272</td>\n",
              "      <td>0.286315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>567</td>\n",
              "      <td>2020-10-01</td>\n",
              "      <td>2020-12-31</td>\n",
              "      <td>DDPG</td>\n",
              "      <td>0.307694</td>\n",
              "      <td>0.313013</td>\n",
              "      <td>0.478353</td>\n",
              "      <td>0.403345</td>\n",
              "      <td>0.403345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>630</td>\n",
              "      <td>2020-12-31</td>\n",
              "      <td>2021-04-05</td>\n",
              "      <td>A2C</td>\n",
              "      <td>0.095756</td>\n",
              "      <td>0.025216</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.052197</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>693</td>\n",
              "      <td>2021-04-05</td>\n",
              "      <td>2021-07-02</td>\n",
              "      <td>PPO</td>\n",
              "      <td>0.1701</td>\n",
              "      <td>0.185656</td>\n",
              "      <td>0.175086</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>756</td>\n",
              "      <td>2021-07-02</td>\n",
              "      <td>2021-10-01</td>\n",
              "      <td>A2C</td>\n",
              "      <td>0.267724</td>\n",
              "      <td>0.145849</td>\n",
              "      <td>-0.109837</td>\n",
              "      <td>0.260524</td>\n",
              "      <td>-0.109837</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>819</td>\n",
              "      <td>2021-10-01</td>\n",
              "      <td>2021-12-31</td>\n",
              "      <td>A2C</td>\n",
              "      <td>0.375665</td>\n",
              "      <td>0.153043</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.123922</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>882</td>\n",
              "      <td>2021-12-31</td>\n",
              "      <td>2022-04-01</td>\n",
              "      <td>A2C</td>\n",
              "      <td>-0.026209</td>\n",
              "      <td>-0.07406</td>\n",
              "      <td>-0.086534</td>\n",
              "      <td>-0.12515</td>\n",
              "      <td>-0.099551</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>945</td>\n",
              "      <td>2022-04-01</td>\n",
              "      <td>2022-07-05</td>\n",
              "      <td>DDPG</td>\n",
              "      <td>-0.166345</td>\n",
              "      <td>-0.277426</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.211532</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2122e869-5ec1-48a1-b545-4b033f27fa50')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2122e869-5ec1-48a1-b545-4b033f27fa50 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2122e869-5ec1-48a1-b545-4b033f27fa50');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7602d1e2-3533-444d-b2c1-dda7d21c46d0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7602d1e2-3533-444d-b2c1-dda7d21c46d0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7602d1e2-3533-444d-b2c1-dda7d21c46d0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_62044cec-ac9b-4387-880c-fdc477931c09\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_summary')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_62044cec-ac9b-4387-880c-fdc477931c09 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_summary');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_summary",
              "summary": "{\n  \"name\": \"df_summary\",\n  \"rows\": 14,\n  \"fields\": [\n    {\n      \"column\": \"Iter\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 126,\n        \"max\": 945,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          693,\n          819,\n          126\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Val Start\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 14,\n        \"samples\": [\n          \"2021-04-05\",\n          \"2021-10-01\",\n          \"2019-01-02\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Val End\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 14,\n        \"samples\": [\n          \"2021-07-02\",\n          \"2021-12-31\",\n          \"2019-04-03\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Model Used\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"DDPG\",\n          \"PPO\",\n          \"A2C\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"A2C Sharpe\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": -0.16634487535807727,\n        \"max\": 0.7012363038647612,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.17010016570693268,\n          0.3756647371401744,\n          0.3929534733700651\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PPO Sharpe\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": -0.2821199045435727,\n        \"max\": 0.3920950808248181,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.18565586543505946,\n          0.15304252092176704,\n          0.3920950808248181\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DDPG Sharpe\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": -0.10983748480515784,\n        \"max\": 0.6149495396801921,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          -0.10983748480515784,\n          0.12361139053508766,\n          0.4478704320384481\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SAC Sharpe\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": -0.21153207260247814,\n        \"max\": 0.6149495396801921,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          -0.12515022943996468,\n          0.12392215163579824,\n          0.2880277254707075\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TD3 Sharpe\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": -0.10983748480515784,\n        \"max\": 0.44960660570223726,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          -0.10983748480515784,\n          0.020708898814118054,\n          0.40969072292960185\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    }
  ]
}