{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZX8O8OC0WUfO"
      },
      "outputs": [],
      "source": [
        "!pip install yfinance"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import kurtosis\n",
        "import math\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import GRU, Dense, Dropout\n",
        "import numpy as np\n",
        "from scipy.stats import levy_stable"
      ],
      "metadata": {
        "id": "LoM8bzylWd9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = '2012-01-01'\n",
        "end = '2023-1-31'\n",
        "interval = '1d'\n",
        "\n",
        "symbols = ['AAPL', 'NVDA', 'MSFT', 'AMZN', 'META', 'GOOGL', 'BRK.B','GOOG','AVGO', 'TSLA', 'LLY', 'JPM', 'XOM', 'UNH', 'V', 'MA', 'HD', 'PG', 'COST', 'JNJ', 'WMT', 'ABBV', 'NFLX', 'BAC', 'CRM']\n",
        "data = pd.DataFrame()\n",
        "\n",
        "for x in symbols:\n",
        "    current_data = yf.download(x, start=start, end=end, interval=interval)\n",
        "    current_data.columns = current_data.columns.get_level_values(0)\n",
        "    current_data.reset_index(inplace=True)\n",
        "    current_data['Date'] = current_data['Date'].dt.date\n",
        "    current_data['Symbol'] = x\n",
        "    data = pd.concat([data, current_data], ignore_index=True)\n",
        "\n",
        "data[\"AnnReturn\"] = data['Adj Close'].pct_change()\n",
        "data['v20'] = data['AnnReturn'].rolling(window = 20).var() * 252\n",
        "data['k20'] = data['AnnReturn'].rolling(window = 20).apply(kurtosis, raw = True)\n",
        "data['vol10'] = data['Volume'].rolling(window=10).mean()\n",
        "data['vema12'] = data['Volume'].ewm(span=12, adjust=False).mean()\n",
        "data['vstd20'] = data['Volume'].rolling(window=20).std()\n",
        "data['ar'] = (data['High'].rolling(window=26).sum() - data['Open'].rolling(window=26).sum()) / (data['Open'].rolling(window=26).sum() - data['Low'].rolling(window=26).sum()) * 100\n",
        "data['br'] = (data['High'].rolling(window=26).sum() - data['Close'].shift(1).rolling(window=26).sum()) / (data['Close'].shift(1).rolling(window=26).sum() - data['Low'].rolling(window=26).sum()) * 100\n",
        "\n",
        "\n",
        "data = data.dropna()\n",
        "data = data.reset_index(drop=True)\n",
        "data.columns.name = None\n",
        "data['close_change_pct'] = data.groupby('Symbol')['Close'].pct_change()\n",
        "\n",
        "data['Label'] = 0\n",
        "for x in symbols:\n",
        "    pct_mean = data[data['Symbol'] == x]['close_change_pct'].mean()\n",
        "    pct_std = data[data['Symbol'] == x]['close_change_pct'].std()\n",
        "    for j in data[data['Symbol'] == x].index:\n",
        "        if data.at[j, 'close_change_pct'] >= (pct_mean + pct_std):\n",
        "            data.at[j, 'Label'] = 2\n",
        "        elif 0 < data.at[j, 'close_change_pct'] < (pct_mean + pct_std):\n",
        "            data.at[j, 'Label'] = 1\n",
        "        else:\n",
        "            data.at[j, 'Label'] = 0\n"
      ],
      "metadata": {
        "id": "6uxBhD1sWix3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data[data['Label'] != 2].reset_index(drop=True)\n",
        "data = data.sort_values(by=['Date']).reset_index(drop=True)\n",
        "y = data['Label'].values\n",
        "sym = data['Symbol'].values\n",
        "train = data.drop(columns=['Label', 'close_change_pct', 'Symbol', 'Date'])"
      ],
      "metadata": {
        "id": "_J6_ppVZWkBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_raw = np.lib.stride_tricks.sliding_window_view(train.values, window_shape=(30, train.shape[1]))[:-1, :, :]\n",
        "X_raw = X_raw[:, 0, :, :]\n",
        "y_seq = y[30:]\n",
        "\n",
        "X_scaled = np.array([StandardScaler().fit_transform(seq) for seq in X_raw])\n",
        "x_train, x_test, y_train, y_test = train_test_split(X_scaled, y_seq, test_size=0.2, shuffle=False, random_state=42)\n",
        "x_train.shape"
      ],
      "metadata": {
        "id": "yxxW7EPWWmhW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (x_train.shape[1], x_train.shape[2])"
      ],
      "metadata": {
        "id": "xQrGkVLdWoYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cuckoo Search optimization algorithm, set the probability Pa of the host bird to find foreign eggs in the nest\n",
        "# to be 0.25, the step scaling factor α in Levy’s flight is 0.1, the β coefficient is 1.5, and the population\n",
        "# size is 18.\n",
        "\n",
        "# In the CS-GRU stock selection model, the Cuckoo Search optimization algorithm is\n",
        "# used to optimize the number of neuron nodes in the GRU layer and full connection layer\n",
        "# in GRU neural network architecture. In the process of parameter optimization, this paper\n",
        "# sets the maximum number of optimization iterations to 100, and the value range of the\n",
        "# four parameters to be optimized is [0, 200].\n",
        "\n",
        "h_neurons = [10, 30, 20, 15]\n",
        "shape = (x_train.shape[1], x_train.shape[2])\n",
        "label_count = 1\n",
        "\n",
        "def gru(h_neurons, shape, label_count=1):\n",
        "    gru_model = Sequential()\n",
        "    gru_model.add(GRU(int(h_neurons[0]), input_shape=shape, return_sequences=False))\n",
        "    gru_model.add(tf.keras.layers.ReLU())\n",
        "    gru_model.add(Dropout(0.5))\n",
        "    gru_model.add(Dense(int(h_neurons[1]), activation='relu'))\n",
        "    gru_model.add(Dropout(0.5))\n",
        "    gru_model.add(Dense(int(h_neurons[2]), activation='relu'))\n",
        "    gru_model.add(Dropout(0.5))\n",
        "    gru_model.add(Dense(int(h_neurons[3]), activation='relu'))\n",
        "    gru_model.add(Dropout(0.5))\n",
        "    gru_model.add(Dense(label_count, activation='sigmoid')) #chose sigmoid over softmax due to binary lables (1/0)\n",
        "\n",
        "    gru_model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return gru_model\n",
        "\n",
        "def fitness_function(neurons, shape, X_train, X_test, y_train, y_test):\n",
        "    h_neurons = neurons.astype(int)\n",
        "    model = gru(h_neurons, shape, label_count)\n",
        "    model.fit(X_train, y_train, epochs=3, batch_size=32, verbose=0)\n",
        "    _, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "    return accuracy\n",
        "\n",
        "def levy_flight(beta):\n",
        "    sigma = (math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n",
        "             (math.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n",
        "    u = np.random.normal(0, sigma, 4)\n",
        "    v = np.random.normal(0, 1, 4)\n",
        "    step = u / (np.abs(v) ** (1 / beta))\n",
        "    return step\n",
        "\n",
        "def cuckoo_search(input_shape, X_train, y_train, X_test, y_test,\n",
        "                  population_size, max_iterations, pa, alpha, beta,\n",
        "                  parameter_range):\n",
        "\n",
        "    population = np.random.randint(parameter_range[0], parameter_range[1], (population_size, 4))\n",
        "    fitness = np.array([fitness_function(ind, input_shape, X_train, X_test, y_train, y_test)\n",
        "                        for ind in population])\n",
        "\n",
        "    for iteration in range(max_iterations):\n",
        "        for i in range(population_size):\n",
        "            step = alpha * levy_flight(beta)\n",
        "            new_solution = np.clip(population[i] + step, *parameter_range).astype(int)\n",
        "            new_fitness = fitness_function(new_solution, input_shape, X_train, X_test, y_train, y_test)\n",
        "            if new_fitness > fitness[i]:\n",
        "                population[i] = new_solution\n",
        "                fitness[i] = new_fitness\n",
        "\n",
        "        num_discovered = int(pa * population_size)\n",
        "        for _ in range(num_discovered):\n",
        "            idx = np.random.randint(population_size)\n",
        "            population[idx] = np.random.randint(parameter_range[0], parameter_range[1], 4)\n",
        "            fitness[idx] = fitness_function(population[idx], input_shape, X_train, X_test, y_train, y_test)\n",
        "\n",
        "        best_idx = np.argmax(fitness)\n",
        "        print(f\"fitness: {fitness[best_idx]}, nueron setup: {population[best_idx]}\")\n",
        "\n",
        "    best_solution = population[best_idx]\n",
        "    return best_solution\n",
        "\n",
        "nueron_setup = cuckoo_search(\n",
        "    input_shape=shape,\n",
        "    X_train=x_train,\n",
        "    y_train=y_train,\n",
        "    X_test=x_test,\n",
        "    y_test=y_test,\n",
        "    population_size=18,\n",
        "    max_iterations=100,\n",
        "    pa=0.25,\n",
        "    alpha=0.1,\n",
        "    beta=1.5,\n",
        "    parameter_range=(1, 200)\n",
        ")\n",
        "\n",
        "print(nueron_setup)\n",
        "# nueron setup on runs shows: h_neurons = [31, 163, 53, 66]"
      ],
      "metadata": {
        "id": "H7yXQ6e8Wp1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shape = (x_train.shape[1], x_train.shape[2])\n",
        "label_count = 1\n",
        "\n",
        "def gru(h_neurons, shape, label_count=1):\n",
        "    gru_model = Sequential()\n",
        "    gru_model.add(GRU(int(h_neurons[0]), input_shape=shape, return_sequences=False))\n",
        "    gru_model.add(tf.keras.layers.ReLU())\n",
        "    gru_model.add(Dropout(0.5))\n",
        "    gru_model.add(Dense(163, activation='relu'))\n",
        "    gru_model.add(Dropout(0.5))\n",
        "    gru_model.add(Dense(53, activation='relu'))\n",
        "    gru_model.add(Dropout(0.5))\n",
        "    gru_model.add(Dense(66, activation='relu'))\n",
        "    gru_model.add(Dropout(0.5))\n",
        "    gru_model.add(Dense(label_count, activation='sigmoid'))\n",
        "\n",
        "    gru_model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return gru_model\n",
        "\n",
        "\n",
        "def evaluate_gru(x_train, y_train, x_test, y_test, h_neurons):\n",
        "    input_shape = x_train.shape[1:]\n",
        "    label_count = 1\n",
        "    model = gru(h_neurons, input_shape, label_count=label_count)\n",
        "    model.fit(x_train, y_train, epochs=50, batch_size=32, verbose=1)\n",
        "    predictions = model.predict(x_test)\n",
        "    predicted_labels = (predictions > 0.5).astype(int)\n",
        "    print(f\"Accuracy: {accuracy_score(y_test, predicted_labels)}\")\n",
        "    print(f\"Precision: {precision_score(y_test, predicted_labels, average='binary')}\")\n",
        "    print(f\"Recall: {recall_score(y_test, predicted_labels, average='binary')}\")\n",
        "    print(f\"F1 Score: {f1_score(y_test, predicted_labels, average='binary')}\")\n",
        "\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "dummy_var = evaluate_gru(x_train, y_train, x_test, y_test, h_neurons) #dummy var to run call the function"
      ],
      "metadata": {
        "id": "s_oOb2g5XQpa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}